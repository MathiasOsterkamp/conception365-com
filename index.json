[{"date":"1619049600","url":"https://conception365.com/post/2021-04-22-spfx-2019-prettier-eslint/","title":"SPFX 2019 eslint and prettier","summary":"SPFX 2019 eslint and prettier For our current projects we used tslint and suffered for some problems. First main concern was, that VSCode was not able to give full feedback about code problems. Later on execution of gulp build all errors where thrown. Furthermore we got some conflicts with prettier solution and it was a hell to understand the current used rules from tslint. Also the tslint performance was very awful.","content":"SPFX 2019 eslint and prettier For our current projects we used tslint and suffered for some problems. First main concern was, that VSCode was not able to give full feedback about code problems. Later on execution of gulp build all errors where thrown. Furthermore we got some conflicts with prettier solution and it was a hell to understand the current used rules from tslint. Also the tslint performance was very awful. We know it is deprecated for a while source and now its time to get rid of it.\nWe decided to move to current state of art eslint and there was a good starting point from Sergei Sergeev. source. From my point of view we cannot come alone with the eslint rule set, we need a good code formatter solution, too. Luckily there is a good solution with prettier, it works with a combined rule set. Here i will introduce a full demo solution for SPFX 2019 with react.\nYou can find the source code here.\nESLint and prettier motivation I found a really god explanation from Joel Reis, why it makes sense to use these tools together\n When building apps, it\u0026rsquo;s important to have a good setup of automated and manual tools that ensures the best standards and code quality. Each project must have a linting tool to fulfill these needs. Both tools are configurable and they work well together, each one having a different linting responsibility between programming and stylistic errors, making it easy to catch errors.\nESLint is one of the most used linting tools and there is a reason for it. Highly configurable, it has a huge adoption from the community having hundreds of open-source configurations and plugins. It allows the configuration of several options like coding rules, environments, parser options, extend configurations, and use plugins.\nOn one hand, ESLint is responsible for checking against programming errors, on the other hand, we have Prettier an opinionated code formatter capable of finding any stylistic errors. It comes with some code style standards and is also easy to configure. It\u0026rsquo;s easy to integrate with ESLint and has Code Editor extensions that can format the code on save!\n \u0026ldquo;Joel Reis\u0026rdquo; source\nPrerequisite For SPFX 2019 we have normally to use Node version 8, this is not more possible with eslint and we have to upgrade to Node version 10. The good news is, we had very good experiences to using this newer version and no major issues about that. So just check your node version.\nnode -v v10.22.0 Packages We need packages for eslint and prettier in our package.json under devDependencies section, we also need a fresh typescript version:\nPackage.json\n\u0026#34;@typescript-eslint/eslint-plugin\u0026#34;: \u0026#34;^4.22.0\u0026#34;, \u0026#34;@typescript-eslint/parser\u0026#34;: \u0026#34;^4.22.0\u0026#34;, \u0026#34;eslint\u0026#34;: \u0026#34;^7.24.0\u0026#34;, \u0026#34;eslint-config-prettier\u0026#34;: \u0026#34;^8.2.0\u0026#34;, \u0026#34;eslint-plugin-prettier\u0026#34;: \u0026#34;^3.4.0\u0026#34;, \u0026#34;eslint-plugin-react\u0026#34;: \u0026#34;^7.23.2\u0026#34;, \u0026#34;gulp\u0026#34;: \u0026#34;~3.9.1\u0026#34;, \u0026#34;gulp-eslint\u0026#34;: \u0026#34;^6.0.0\u0026#34;, \u0026#34;prettier\u0026#34;: \u0026#34;2.2.1\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;3.6.5\u0026#34; Or with command line\nnpm i --save-dev @typescript-eslint/eslint-plugin @typescript-eslint/parser eslint eslint-config-prettier eslint-plugin-prettier eslint-plugin-react gulp gulp-eslint prettier typescript@3.6.5 ESLint config Our main configuration goes to .eslintrc.json. We register on extensions 4 rule sets, you will find several specific details about your rules:\n{ \u0026#34;root\u0026#34;: true, \u0026#34;env\u0026#34;: { \u0026#34;browser\u0026#34;: true, \u0026#34;node\u0026#34;: true }, \u0026#34;extends\u0026#34;: [ \u0026#34;eslint:recommended\u0026#34;, \u0026#34;plugin:react/recommended\u0026#34;, \u0026#34;plugin:@typescript-eslint/recommended\u0026#34;, \u0026#34;prettier\u0026#34; ], \u0026#34;parser\u0026#34;: \u0026#34;@typescript-eslint/parser\u0026#34;, \u0026#34;parserOptions\u0026#34;: { \u0026#34;ecmaFeatures\u0026#34;: { \u0026#34;jsx\u0026#34;: true }, \u0026#34;ecmaVersion\u0026#34;: 12, \u0026#34;sourceType\u0026#34;: \u0026#34;module\u0026#34; }, \u0026#34;plugins\u0026#34;: [\u0026#34;react\u0026#34;, \u0026#34;@typescript-eslint\u0026#34;, \u0026#34;prettier\u0026#34;], \u0026#34;rules\u0026#34;: { \u0026#34;prettier/prettier\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;no-use-before-define\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;@typescript-eslint/no-use-before-define\u0026#34;: [\u0026#34;error\u0026#34;], \u0026#34;no-multiple-empty-lines\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;no-multi-spaces\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;no-var\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;@typescript-eslint/ban-ts-comment\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;semi\u0026#34;: [\u0026#34;error\u0026#34;, \u0026#34;always\u0026#34;] }, \u0026#34;ignorePatterns\u0026#34;: [ \u0026#34;*.js\u0026#34;, \u0026#34;**/coverage\u0026#34;, \u0026#34;**/dist\u0026#34;, \u0026#34;**/etc\u0026#34;, \u0026#34;**/lib\u0026#34;, \u0026#34;**/sharepoint\u0026#34;, \u0026#34;**/lib-amd\u0026#34;, \u0026#34;**/lib-commonjs\u0026#34;, \u0026#34;**/node_modules\u0026#34;, \u0026#34;**/temp\u0026#34;, \u0026#34;**/*.scss.ts\u0026#34; ], \u0026#34;settings\u0026#34;: { \u0026#34;react\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;detect\u0026#34; } } } extends  eslint:recommended basic eslint rules plugin:react/recommended react based rules plugin:@typescript-eslint/recommended our typescript specific rules prettier rules to hold format and eslint rules together  plugins Just register our functions\nrules Here you can override rules by your own project specific settings. For bigger projects it maybe makes sense to create an own rule set.\nignorePatterns We like to exclude everything what is not our source code.\nsettings We need for react a specific setting, to detect our react version.\nIntegration Now we like to replace our default tslint build process with custom eslint task in gulpfile.js. We create a new prebuild Task for eslint and disable tslint. Futhermore we need to register the current typescript version.\n\u0026#34;use strict\u0026#34;; const build = require(\u0026#34;@microsoft/sp-build-web\u0026#34;); const eslint = require(\u0026#34;gulp-eslint\u0026#34;); const typeScriptConfig = require(\u0026#34;@microsoft/gulp-core-build-typescript/lib/TypeScriptConfiguration\u0026#34;); const buildtypescript = require(\u0026#34;@microsoft/gulp-core-build-typescript\u0026#34;); typeScriptConfig.TypeScriptConfiguration.setTypescriptCompiler( require(\u0026#34;typescript\u0026#34;) ); buildtypescript.tslint.enabled = false; const eslintSubTask = build.subTask( \u0026#34;eslint\u0026#34;, function (gulp, buildOptions, done) { return ( gulp .src([\u0026#34;src/**/*.{ts,tsx}\u0026#34;]) // eslint() attaches the lint output to the \u0026#34;eslint\u0026#34; property  // of the file object so it can be used by other modules.  .pipe(eslint()) // eslint.format() outputs the lint results to the console.  // Alternatively use eslint.formatEach() (see Docs).  .pipe(eslint.format()) // To have the process exit with an error code (1) on  // lint error, return the stream and pipe to failAfterError last.  .pipe(eslint.failAfterError()) ); } ); build.addSuppression( `Warning - [sass] The local CSS class \u0026#39;ms-Grid\u0026#39; is not camelCase and will not be type-safe.` ); build.rig.addPreBuildTask(build.task(\u0026#34;eslint-task\u0026#34;, eslintSubTask)); build.initialize(require(\u0026#34;gulp\u0026#34;)); Prettier We need a basic configuration file .prettierrc.yaml to set our prettier. You can find here the most important options.\n{ \u0026#34;singleQuote\u0026#34;: true, # use quotes instead of double quotes \u0026#34;jsxSingleQuote\u0026#34;: true, # single quotes for jsx \u0026#34;jsxBracketSameLine\u0026#34;: true, # closing bracked in same line \u0026#34;arrowParens\u0026#34;: \u0026#34;always\u0026#34;, # use bracked in arrow functions \u0026#34;printWidth\u0026#34;: 120, # preferred width (not same as eslint max-length) \u0026#34;tabWidth\u0026#34;: 2, # number of spaces \u0026#34;useTabs\u0026#34;: false, # spaces instead of tabs \u0026#34;semi\u0026#34;: true, # semicolons at ends of statement \u0026#34;trailingComma\u0026#34;: \u0026#34;none\u0026#34;, # removes trailing comma inside objects \u0026#34;htmlWhitespaceSensitivity\u0026#34;: \u0026#34;strict\u0026#34;, # whitespace inside html is significant \u0026#34;endOfLine\u0026#34;: \u0026#34;auto\u0026#34;, # correct end of line } And we need to ignore some files .prettierignore:\n# Ignore artifacts: sharepoint lib node_modules temp dist Plugins for VSCode VSCode extensions are helping us a lot to make the integration with eslint and prettier. You will find these two extensions here:\n dbaeumer.vscode-eslint esbenp.prettier-vscode  To work i recommend to update your settings.json inside .vscode folder:\n\u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, #enable prettier as default formatter \u0026#34;prettier.configPath\u0026#34;: \u0026#34;./.prettierrc.yaml\u0026#34;, #set config file \u0026#34;editor.formatOnSave\u0026#34;: true #set format on save Run Now you also can format your complete project by running just one line\nPS C:\\daten\\git\\spfx-2019-prettier\u0026gt; npm run format \u0026gt; spfx-2019-prettier@0.0.1 format C:\\daten\\git\\spfx-2019-prettier \u0026gt; npx prettier --write . --config .prettierrc.yaml .eslintrc.json 105ms .prettierrc.yaml 85ms .vscode\\extensions.json 9ms .vscode\\launch.json 47ms .vscode\\settings.json 13ms .yo-rc.json 21ms config\\config.json 27ms config\\copy-assets.json 12ms config\\deploy-azure-storage.json 15ms Furthermore you can also use the eslint fix option.\nPS C:\\daten\\git\\spfx-2019-prettier\u0026gt; npm run fix \u0026gt; spfx-2019-prettier@0.0.1 fix C:\\daten\\git\\spfx-2019-prettier \u0026gt; npx eslint src/ --fix --ext .ts --ext .tsx C:\\daten\\git\\spfx-2019-prettier\\src\\webparts\\helloWorld\\components\\HelloWorld.tsx 6:75 error Don\u0026#39;t use `{}` as a type. `{}` actually means \u0026#34;any non-nullish value\u0026#34;. - If you want a type meaning \u0026#34;any object\u0026#34;, you probably want `Record\u0026lt;string, unknown\u0026gt;` instead. - If you want a type meaning \u0026#34;any value\u0026#34;, you probably want `unknown` instead. - If you want a type meaning \u0026#34;empty object\u0026#34;, you probably want `Record\u0026lt;string, never\u0026gt;` instead @typescript-eslint/ban-types ✖ 1 problem (1 error, 0 warnings) npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! spfx-2019-prettier@0.0.1 fix: `npx eslint src/ --fix --ext .ts --ext .tsx` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the spfx-2019-prettier@0.0.1 fix script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: You should fix your errors:\nexport default class HelloWorld extends React.Component\u0026lt;IHelloWorldProps, unknown\u0026gt; { And you will run a pretty fast build with everything together:\nPS C:\\daten\\git\\spfx-2019-prettier\u0026gt; npm run package \u0026gt; spfx-2019-prettier@0.0.1 package C:\\daten\\git\\spfx-2019-prettier \u0026gt; gulp clean \u0026amp;\u0026amp; gulp bundle \u0026amp;\u0026amp; gulp package-solution Build target: DEBUG [20:56:49] Using gulpfile C:\\daten\\git\\spfx-2019-prettier\\gulpfile.js [20:56:49] Starting gulp [20:56:49] Starting \u0026#39;clean\u0026#39;... [20:56:49] Starting subtask \u0026#39;clean\u0026#39;... [20:56:49] Finished subtask \u0026#39;clean\u0026#39; after 25 ms [20:56:49] Finished \u0026#39;clean\u0026#39; after 32 ms [20:56:50] ==================[ Finished ]================== [20:56:50] Project spfx-2019-prettier version: 0.0.1 [20:56:50] Build tools version: 3.2.7 [20:56:50] Node version: v10.22.0 [20:56:50] Total duration: 6.41 s Build target: DEBUG [20:56:58] Using gulpfile C:\\daten\\git\\spfx-2019-prettier\\gulpfile.js [20:56:58] Starting gulp [20:56:58] Starting \u0026#39;bundle\u0026#39;... [20:56:58] Starting subtask \u0026#39;configure-sp-build-rig\u0026#39;... [20:56:58] Finished subtask \u0026#39;configure-sp-build-rig\u0026#39; after 25 ms [20:56:58] Starting subtask \u0026#39;pre-copy\u0026#39;... [20:56:58] Finished subtask \u0026#39;pre-copy\u0026#39; after 42 ms [20:56:58] Starting subtask \u0026#39;eslint\u0026#39;... [20:57:04] Finished subtask \u0026#39;eslint\u0026#39; after 5.61 s From now on you have a good boilerplate to use eslint and prettier together on your spfx 2019 projects.\n","tags":["SP2019","SPFX","eslint","prettier"],"section":"post"},{"date":"1607731200","url":"https://conception365.com/post/2020-12-12-managed-metadata-migration/","title":"Managed Metadata Migration","summary":"Managed Metadata Migration Managed metadata is a formal taxonomy classification system. A taxonomy groups the words, labels, and terms that describe something, and then arranges the groups into a hierarchy. You can learn more basics and wordings on microsoft docs. Mostly it is simple called term store.\nWhere are my data stored? The first common question for migration is, where actual the term store data are stored. The short answer is, everything important is stored in Managed Metadata SQL Database of the service application.","content":"Managed Metadata Migration Managed metadata is a formal taxonomy classification system. A taxonomy groups the words, labels, and terms that describe something, and then arranges the groups into a hierarchy. You can learn more basics and wordings on microsoft docs. Mostly it is simple called term store.\nWhere are my data stored? The first common question for migration is, where actual the term store data are stored. The short answer is, everything important is stored in Managed Metadata SQL Database of the service application. To get a bit deeper look we have to analyze the field structure.\nHow the fields are structured? A typical Sharepoint taxonomy field looks the following way (source).\n   DisplayName InternalName Data Type Visible Value Data Format Created By     [YourColumnName] [YourColumnName] TaxonomyFieldType[Mult] Yes 2;#Chennai WSS Id; Name of Team User   [YourColumnName]_0 [YourColumnName]TaxHTField0 Note No Chennai c61d9028-824f-446e-9389-eb9515813a42 Name of Term   Taxonomy Catch All Column TaxCatchAll Lookup No   SharePoint    We see here basically, there is one column [YourColumnName] for your term display value and another column [YourColumnName]TaxHTField0 for the term ID. But this is the internal structure, most time you handle with taxonomy fields by using the API, here everything internal is handled, and you don\u0026rsquo;t have to worry about the internal field. Sample for REST taxonomy structure\n{ \u0026#34;MetaSingleField\u0026#34;: { \u0026#34;__metadata\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;SP.Taxonomy.TaxonomyFieldValue\u0026#34; }, \u0026#34;Label\u0026#34;: \u0026#34;1289\u0026#34;, \u0026#34;TermGuid\u0026#34;: \u0026#34;0b032022-d156-49eb-9a48-904df5411349\u0026#34;, \u0026#34;WssId\u0026#34;: 1289 }, \u0026#34;MetaMultiField\u0026#34;: { \u0026#34;__metadata\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Collection(SP.Taxonomy.TaxonomyFieldValue)\u0026#34; }, \u0026#34;results\u0026#34;: [ { \u0026#34;Label\u0026#34;: \u0026#34; Label ABC\u0026#34;, \u0026#34;TermGuid\u0026#34;: \u0026#34;158a84f4-e5ff-440b-b55f-d30b0f77c402\u0026#34;, \u0026#34;WssId\u0026#34;: 1291 }, { \u0026#34;Label\u0026#34;: \u0026#34; Label DEF\u0026#34;, \u0026#34;TermGuid\u0026#34;: \u0026#34;03d2d388-a863-4f5d-818d-d71d948f763d\u0026#34;, \u0026#34;WssId\u0026#34;: 1290 } ] }, \u0026#34;TaxCatchAll\u0026#34;: { \u0026#34;results\u0026#34;: [ { \u0026#34;__metadata\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;158a84f4-e5ff-440b-b55f-d30b0f77c402\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SP.Data.TaxonomyHiddenListListItem\u0026#34; }, \u0026#34;ID\u0026#34;: 1291, \u0026#34;Term\u0026#34;: \u0026#34;Label ABC\u0026#34; }, { \u0026#34;__metadata\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;03d2d388-a863-4f5d-818d-d71d948f763d\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SP.Data.TaxonomyHiddenListListItem\u0026#34; }, \u0026#34;ID\u0026#34;: 1290, \u0026#34;Term\u0026#34;: \u0026#34;Label DEF\u0026#34; }, { \u0026#34;__metadata\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;0b032022-d156-49eb-9a48-904df5411349\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SP.Data.TaxonomyHiddenListListItem\u0026#34; }, \u0026#34;ID\u0026#34;: 1289, \u0026#34;Term\u0026#34;: \u0026#34;Label XYZ\u0026#34; } ] } } Why there is a hidden list? On the look of the field structure you also see a reference for WSS or TaxonomyHiddenList. The answer is, that is a caching system to allow get the taxonomy data faster from list only be a simple lookup to this hidden list. The good about this is, you d\u0026rsquo;ont have to really care about that fact. If you change taxonomy field values, SharePoint internal has Event Receivers to handle an update to this hidden list. If you are change the taxonomy value inside the term store, there is also an hourly update timer job, it makes an update to the hidden list information. So the result the quick conclusion from migration perspective is for that:\n Don\u0026rsquo;t care about hidden list on migration!  But there is a site collection and a global term store? Yes, the only real difference is the availability. So global term sets are visible on every site collection. Local term sets are only visible to a single site collection.\n Both sorts of terms are store on Managed Metadatabase  How are managed metadata fields and term store connected? A really important fact is, how the term store and fields are connected. We see more details by looking on the field structure.\n\u0026lt;Field Type=\u0026#34;TaxonomyFieldType\u0026#34; DisplayName=\u0026#34;Custom (web)\u0026#34; List=\u0026#34;Lists/TaxonomyHiddenList\u0026#34; WebId=\u0026#34;~sitecollection\u0026#34; ShowField=\u0026#34;Term1033\u0026#34; Required=\u0026#34;FALSE\u0026#34; EnforceUniqueValues=\u0026#34;FALSE\u0026#34; Group=\u0026#34;_Custom\u0026#34; ID=\u0026#34;{fce6a8e2-23e8-49c2-9bad-a534555296bb}\u0026#34; SourceID=\u0026#34;{5e68c9eb-5efe-4bcc-b8db-93d38d797fbe}\u0026#34; StaticName=\u0026#34;__Custom\u0026#34; Name=\u0026#34;__Custom\u0026#34; Overwrite=\u0026#34;TRUE\u0026#34;\u0026gt; Default /\u0026gt; \u0026lt;Customization\u0026gt; \u0026lt;ArrayOfProperty\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;SspId\u0026lt;/Name\u0026gt; \u0026lt;Value xmlns:q1=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; p4:type=\u0026#34;q1:string\u0026#34; xmlns:p4=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;b98dd270-8577-4db8-99e1-b9e894624fdb \u0026lt;/Value\u0026gt; \u0026lt;/Property\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;GroupId\u0026lt;/Name\u0026gt; \u0026lt;/Property\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;TermSetId\u0026lt;/Name\u0026gt; \u0026lt;Value xmlns:q2=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; p4:type=\u0026#34;q2:string\u0026#34; xmlns:p4=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;b7ae10cd-6c7c-4386-a1f2-7abec8e759e1 \u0026lt;/Value\u0026gt; \u0026lt;/Property\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;AnchorId\u0026lt;/Name\u0026gt; \u0026lt;Value xmlns:q3=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; p4:type=\u0026#34;q3:string\u0026#34; xmlns:p4=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;00000000-0000-0000-0000-000000000000 \u0026lt;/Value\u0026gt; \u0026lt;/Property\u0026gt; ... \u0026lt;/ArrayOfProperty\u0026gt; \u0026lt;/Customization\u0026gt; \u0026lt;/Field\u0026gt; We find two important values:\n SspId: This is the ID of your managed metadata service application TermSetId: This is the ID of your termset  The consequence of these two information on migration perspective is.\n You need your Managed Metadata SQL Database and a related service application to keep your term store ID (SspID) You need always correct termset and term IDs for migration  Can I import or export my termsets? There are several import and export mechanisms here some details about:\n Taxonomy Import (details): It allows only to import simple csv based termsets without IDs, not for migration Export-SPMetadataWebServicePartitionData (details): It\u0026rsquo;s only for server to server migration from the same version Powershell Skripts (sample): You will keep your term set IDs, it can work for simple migrations only for term sets. If you have related data on your site collections, your term store ID could not match. Possible is first a database migration and afterwards a delta migration Migration tools: Mostly are relative close to Powershell Scripts PNP Powershell: Same like Powershell Scripts  In general, you have to think on these scenarios on a little more details:\n Handle users are not more available on target system Handle orphaned terms Handle term reuse Handle navigation term sets  How looks a database migration? To move the managed metadata database, take a copy only backup of it from your SQL server and then restore from files in your new SQL server. I took this short sample from here.\nAt this point, you already have a managed metadata service application in your target farm and you need to get it’s globally unique identifier (GUID). Run the following:\nGet-SPServiceApplication | ?{$_.name -like \u0026#34;*meta*\u0026#34;} | ft id You could put that ID in a variable, or you could type it into your next set of commands that attach the new db to the Managed Metadata service application\n$ServiceID = Get-SPServiceApplication | ?{$_.name -like \u0026#34;*meta*\u0026#34;} | ft id $mms = Get-SPServiceApplication -Identity $ServiceID Set-SPMetadataerviceApplication -Identity $mms -DatabaseName \u0026#34;MetaData\u0026#34; The key to this working is that the correct DatabaseName is used. So if your new db is named MetaDataDB, then the above script would need to be modified a little for the -DatabsaseName parameter.\nThe managed metadata navigation should now be working. If it’s not, just go to manage service applications, change the managed metadata database to a database that does not exist, click OK, then change it back. This process causes SharePoint to execute a timer job that syncs the service application up to the database.\n","tags":["SP2019","SP2013","Migration","Managed Metadata"],"section":"post"},{"date":"1581379200","url":"https://conception365.com/post/2020-02-11-orphaned-terms/","title":"Remove Managed Metadata Orphaned Terms","summary":"Remove Managed Metadata Orphaned Terms Problem In some cases you like to get rid of orphaned terms. Terms mostly get orphaned, if you reuse terms and delete the original instances. There is a very good explanation from Mike Morawski how this could happen.\n Not long ago I was working away with the term store though Powershell. I had to remove all of a particular group’s termsets and to do this I ended up calling the Group’s delete function.","content":"Remove Managed Metadata Orphaned Terms Problem In some cases you like to get rid of orphaned terms. Terms mostly get orphaned, if you reuse terms and delete the original instances. There is a very good explanation from Mike Morawski how this could happen.\n Not long ago I was working away with the term store though Powershell. I had to remove all of a particular group’s termsets and to do this I ended up calling the Group’s delete function. It appeared to work just fine, until I later found that I was unable to import terms with GUID’s used previously. This is somewhat of a common problem that developers will come across if they are saving certain terms or termsets and trying to reimport while the others with the same ID still exist.\nHowever, in this case, the entire term store was empty, until I realized that orphaned terms exist. For those of you who do not know the managed metadata service too well, orphaned terms will be created when deleting a term that was reused/pinned elsewhere. Because the original term that the ‘duplicates’ reference doesn’t exist anymore, the terms become orphans and they reside in the system group.\nThese orphaned terms get removed automatically when the duplicates are removed. Supposedly.\nThere appears to be a bug when removing a group through code where in certain cases the orphans never seem to be checked whether or not the duplicates have all been cleaned up. Through code I had to remove termsets one by one, using the group.termsets property, then commit. It seems that trying to do everything in one commit can cause this.\nNotice that the member of area indicates that there are no other terms using this as a reference, yet it still exists!\nAs far as removing the orphaned terms go, I was unable to actually target these terms through code as I would have the following error:\n This operation is invalid in the Orphaned Terms term set.\n Unfortunately I believe this leaves the MMS in a slightly corrupt state, it will still function so long as those GUID’s for the orphans are never used again. I ended up starting fresh because I fortunately ran into this before the code left the development server.\nI wish I could say more about this issue after the fact however this is all I can say for the time being. If you really need to remove these orphans, an idea I had a the time was to create a duplicate of that orphan through code, then remove manually though the interface and see if that causes some sort of event receiver to run through and clear the source term (orphan).\n You can also find some more details about general deleting of terms source.\nSolution There is a easy solution by deleting the terms with PNP Powershell. Prepare your environment:\n\u0026mdash;ps1 Install-Module -Name PnP.PowerShell Delete your terms:\n\u0026mdash;ps1\n$session = Get-PnPTaxonomySession $termStore = $session.TermStores[0] $termSet = Get-PnPTermSet -Identity \u0026ldquo;Orphaned Terms\u0026rdquo; -TermGroup \u0026ldquo;System\u0026rdquo; -Includes \u0026ldquo;Terms\u0026rdquo; if ($termSet) { $terms = $termSet.Terms $terms | ForEach-Object { $_.DeleteObject() } $termStore.CommitAll(); Invoke-PnPQuery }\n Thats everything!\n","tags":["SP2019","Powershell","PNP","Managed Metadata"],"section":"post"}]