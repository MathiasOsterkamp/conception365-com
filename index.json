[{"date":"1635724800","url":"https://conception365.com/post/2021-11-01-powershell-create-navigation/","title":"Powershell - Create Navigation","summary":"Managed Navigation with Powershell Goal Our goal is a complete setup for a test site collection with managed metadata navigation and existing pages with different levels. The challenge is the correct configuration for the site with powershell and also create the correct terms. With the script you can set the amount of navigation entries.\nPreparation We use SharePoint PnP Powershell Package to get help with some tasks.\n PnP Powershell 2019 Download CSOM dlls \u0026ldquo;Microsoft.","content":"Managed Navigation with Powershell Goal Our goal is a complete setup for a test site collection with managed metadata navigation and existing pages with different levels. The challenge is the correct configuration for the site with powershell and also create the correct terms. With the script you can set the amount of navigation entries.\nPreparation We use SharePoint PnP Powershell Package to get help with some tasks.\n PnP Powershell 2019 Download CSOM dlls \u0026ldquo;Microsoft.SharePoint.Client.dll\u0026rdquo; \u0026ldquo;Microsoft.SharePoint.Client.Runtime.dll\u0026rdquo; \u0026ldquo;Microsoft.SharePoint.Client.Taxonomy.dll\u0026rdquo; \u0026ldquo;Microsoft.SharePoint.Client.Publishing.dll\u0026rdquo; from \u0026ldquo;\\Program Files\\Common Files\\Microsoft Shared\\Web Server Extensions\\15\\isapi\\\u0026rdquo; , more details here Create a classic team site collection  Key Points The Invoke-SetupFeatures enables needed features for publishing, what is the requirement.\nThe Invoke-SetupTermSet creates your termset and Invoke-SetupNavigation enables navigation features. We also use Invoke-EnableTagging to allow tagging, that means we also override the default permission behaviour. (Metadata navigation is not visible to users with read permissions) more information.\nFurthermore we collect the page layout item Get-PageLayoutItem and create our terms Invoke-CreateTerms. For each term we create also first a new site page Add-PublishingPageWithContent and connect this page with the new created term.\nThe Invoke-UpdateTaxonomyCache checks changes for taxonomy and avoids save conflicts.\nContent not crawled by search We also had some issues to crawl a big amount (over 3000) of friendly pages from search. That means you can create the pages, but the search index does not collect it any more - at least the friendly url version.\nThe official limit for \u0026ldquo;Number of terms in managed navigation term set\u0026rdquo; from Microsoft is at 2000.\nAfter some research, on a full crawl for example the complete termset is crawled with all pages. That leads to a timeout. You can override this in search central administration here. We had to set it to a high value, the crawl tooks over 12 minutes - so that is maybe in some cases no optimal solution.\nComplete Script # ------------------------------------------------------------------------------------- # Configuration # ------------------------------------------------------------------------------------- $siteurl = \u0026#34;https://contoso.com/sites/sitecollection1\u0026#34; $termSetName = \u0026#34;GlobalNav\u0026#34; # ------------------------------------------------------------------------------------- # Functions # ------------------------------------------------------------------------------------- function Invoke-CreateTerms($context, $PublishingWeb, $PageLayoutItem, $termStore, $termObject, $path, $level, $maxlevel, $maxItemsPerLevel, $overallMax) { $max = $maxItemsPerLevel $level = $level + 1 for ($i = 1; $i -lt $max + 1; $i++) { if ($global:countTerms -lt $overallMax) { if ($path -eq \u0026#34;\u0026#34;) { $newPath = \u0026#34;$i\u0026#34; } else { $newPath = \u0026#34;$($path)_$($i)\u0026#34; } $termName = \u0026#34;Term$newPath\u0026#34; $newpage = Add-PublishingPageWithContent $context $PublishingWeb $PageLayoutItem \u0026#34;$($termName).aspx\u0026#34; $termName $termName $url = $newpage[\u0026#34;FileRef\u0026#34;] $global:countTerms++ Write-Host \u0026#34;Create term $($termName)- $($global:countTerms)/$overallMax...\u0026#34; -f Yellow -NoNewline $newTerm = $termObject.CreateTerm($termName, 1033, [System.Guid]::NewGuid().toString()) $newTerm.SetLocalCustomProperty(\u0026#39;_Sys_Nav_TargetUrl\u0026#39;, $url) Write-Host \u0026#34;Done\u0026#34; -f Green if ($level -lt $maxlevel ) { Invoke-CreateTerms $context $PublishingWeb $PageLayoutItem $termStore $newTerm $newPath $level $maxlevel $maxItemsPerLevel $overallMax } } } $termStore.CommitAll() Invoke-PnPQuery } function Get-PageLayoutItem($PageLayoutName) { $Ctx = Get-PnPContext Write-host -f Yellow \u0026#34;Getting Page Layout...\u0026#34; -NoNewline #Get the Page Layout $RootWeb = $Ctx.Site.RootWeb $MasterPageList = $RootWeb.Lists.GetByTitle(\u0026#39;Master Page Gallery\u0026#39;) $CAMLQuery = New-Object Microsoft.SharePoint.Client.CamlQuery $CAMLQuery.ViewXml = \u0026#34;\u0026lt;View\u0026gt;\u0026lt;Query\u0026gt;\u0026lt;Where\u0026gt;\u0026lt;Eq\u0026gt;\u0026lt;FieldRef Name=\u0026#39;FileLeafRef\u0026#39; /\u0026gt;\u0026lt;Value Type=\u0026#39;Text\u0026#39;\u0026gt;$PageLayoutName\u0026lt;/Value\u0026gt;\u0026lt;/Eq\u0026gt;\u0026lt;/Where\u0026gt;\u0026lt;/Query\u0026gt;\u0026lt;/View\u0026gt;\u0026#34; $PageLayouts = $MasterPageList.GetItems($CAMLQuery) $Ctx.Load($PageLayouts) $Ctx.ExecuteQuery() $PageLayoutItem = $PageLayouts[0] $Ctx.Load($PageLayoutItem) $Ctx.ExecuteQuery() Write-host -f Green \u0026#34;Done\u0026#34; return $PageLayoutItem } function Add-PublishingPageWithContent($Ctx, $PublishingWeb , $PageLayoutItem , $PageName, $PageTitle, $PageContent) { #Create Publishing page Write-host -f Yellow \u0026#34;Creating New Page $PageName ...\u0026#34; -NoNewline $PageInfo = New-Object Microsoft.SharePoint.Client.Publishing.PublishingPageInformation $PageInfo.Name = $PageName $PageInfo.PageLayoutListItem = $PageLayoutItem $Page = $PublishingWeb.AddPublishingPage($PageInfo) $Ctx.ExecuteQuery() $ListItem = $Page.ListItem $Ctx.Load($ListItem) $Ctx.ExecuteQuery() #Update Page Contents $ListItem[\u0026#34;Title\u0026#34;] = $PageTitle $ListItem[\u0026#34;PublishingPageContent\u0026#34;] = $PageContent $ListItem.Update() $Ctx.ExecuteQuery() #Publish the page $ListItem.File.CheckIn([string]::Empty, [Microsoft.SharePoint.Client.CheckinType]::MajorCheckIn) $ListItem.File.Publish([string]::Empty) $Ctx.ExecuteQuery() Write-host -f Green \u0026#34;Done\u0026#34; return $ListItem } function Invoke-SetupFeatures() { #publihsing Infrastructure site feature check $FeaturePublishingInfraSiteId = \u0026#34;f6924d36-2fa8-4f0b-b16d-06b7250180fa\u0026#34; #Site Scoped Publishing Feature $Feature = Get-PnPFeature -Scope Site -Identity $FeaturePublishingInfraSiteId If ($null -eq $Feature.DefinitionId) { Write-host -f Yellow \u0026#34;Activating Publishing Infrastructure Site Feature...\u0026#34; -NoNewline Enable-PnPFeature -Scope Site -Identity $FeaturePublishingInfraSiteId -Force Write-host -f Green \u0026#34;Done\u0026#34; } Else { Write-host -f Yellow \u0026#34;Publishing Infrastructure Site Feature already activated...\u0026#34; -NoNewline Write-host -f Green \u0026#34;Done\u0026#34; } #publishing Infrastructure web feature check $FeaturePublishingInfraWebId = \u0026#34;94c94ca6-b32f-4da9-a9e3-1f3d343d7ecb\u0026#34; $Feature = Get-PnPFeature -Scope Web -Identity $FeaturePublishingInfraWebId If ($null -eq $Feature.DefinitionId) { Write-host -f Yellow \u0026#34;Activating Publishing Infrastructure Web Feature...\u0026#34; Enable-PnPFeature -Scope Web -Identity $FeaturePublishingInfraWebId -Force Write-host -f Green \u0026#34;Done\u0026#34; } Else { Write-host -f Yellow \u0026#34;Publishing Infrastructure Web Feature already activated...\u0026#34; -NoNewline Write-host -f Green \u0026#34;Done\u0026#34; } #Wait complete all Start-Sleep -Seconds 10 } function Invoke-SetupTermSet($termSetName) { $context = Get-PnPContext $CurrentSite = Get-PnPSite $taxonomySession = [Microsoft.SharePoint.Client.Taxonomy.TaxonomySession]::GetTaxonomySession($context) $TermStore = $taxonomySession.GetDefaultSiteCollectionTermStore(); $SiteCollectionTermGroup = $TermStore.GetSiteCollectionGroup($CurrentSite, $false) $context.Load($taxonomySession) $context.Load($SiteCollectionTermGroup) $context.Load($TermStore) Invoke-PnPQuery $termgroupname = $SiteCollectionTermGroup.Name $termSets = Get-PnPTermSet -TermGroup $termgroupname $exists = ($termSets | Where-Object { $_.Name -eq $termSetName } | Measure-Object).Count -gt 0 if ($exists -eq $false ) { Write-Host \u0026#34;Created termset $termSetName ...\u0026#34; -f Yellow -NoNewline $termSet = New-PnPTermSet -Name $termSetName -TermGroup $SiteCollectionTermGroup -Lcid 1033 -IsOpenForTermCreation $TermStore.CommitAll() Write-Host \u0026#34;Done\u0026#34; -f Green } else { Start-Sleep -Seconds 5 Write-Host \u0026#34;Termset already exists $($termSet.Name)\u0026#34; -f Yellow -NoNewline $termSet = Get-PnPTermSet -Identity $termSetName -TermGroup $termgroupname Write-Host \u0026#34;Done\u0026#34; -f Green } } function Invoke-SetupNavigation($termSetName) { Write-Host \u0026#34;Reset Navigation...\u0026#34; -f Yellow -NoNewline $context = Get-PnPContext $CurrentSite = Get-PnPSite $taxonomySession = [Microsoft.SharePoint.Client.Taxonomy.TaxonomySession]::GetTaxonomySession($context) $TermStore = $taxonomySession.GetDefaultSiteCollectionTermStore(); $SiteCollectionTermGroup = $TermStore.GetSiteCollectionGroup($CurrentSite, $false) $termsets = $SiteCollectionTermGroup.TermSets $context.Load($taxonomySession) $context.Load($SiteCollectionTermGroup) $context.Load($termsets) $context.Load($TermStore) Invoke-PnPQuery $navigationTermSet = $termsets | Where-Object { $_.Name -eq $termSetName } $context.Load($navigationTermSet) Invoke-PnPQuery Write-Host \u0026#34;Done\u0026#34; -f Green Write-Host \u0026#34;Set taxonomy navigation...\u0026#34; -f Yellow -NoNewline $context = Get-PnPContext $Web = Get-PnPWeb $navigationSettings = New-Object Microsoft.SharePoint.Client.Publishing.Navigation.WebNavigationSettings $context, $Web $navigationSettings.ResetToDefaults() $navigationSettings.GlobalNavigation.Source = 1 $navigationSettings.CurrentNavigation.Source = 1 $navigationSettings.Update($taxonomySession) Invoke-PnPQuery Start-Sleep -Seconds 2 $context = Get-PnPContext $Web = Get-PnPWeb $navigationSettings = New-Object Microsoft.SharePoint.Client.Publishing.Navigation.WebNavigationSettings $context, $Web $navigationSettings.CurrentNavigation.Source = \u0026#34;taxonomyProvider\u0026#34; $navigationSettings.CurrentNavigation.TermStoreId = $TermStore.Id $navigationSettings.CurrentNavigation.TermSetId = $navigationTermSet.Id $navigationSettings.GlobalNavigation.Source = \u0026#34;taxonomyProvider\u0026#34; $navigationSettings.GlobalNavigation.TermStoreId = $TermStore.Id $navigationSettings.GlobalNavigation.TermSetId = $navigationTermSet.Id $navigationSettings.Update($taxonomySession) $Web.AllProperties[\u0026#34;__IncludeSubSitesInNavigation\u0026#34;] = $True #Show pages in global navigation $Web.AllProperties[\u0026#34;__IncludePagesInNavigation\u0026#34;] = $False #Update Settings $Web.Update() $TermStore.CommitAll() Invoke-PnPQuery Write-Host \u0026#34;Done\u0026#34; -f Green } function Invoke-UpdateTaxonomyCache() { $context = Get-PnPContext Write-Host \u0026#34;Update taxonomy cache...\u0026#34; -f Yellow -NoNewline $TaxonomySession = Get-PnPTaxonomySession $TaxonomySession.UpdateCache() $context.Load($TaxonomySession) Invoke-PnPQuery Write-Host \u0026#34;Done\u0026#34; -f Green } function Invoke-EnableTagging($termSetName) { Write-Host \u0026#34;Enable tagging for termset...\u0026#34; -f Yellow -NoNewline Start-Sleep -Seconds 5 $context = Get-PnPContext $CurrentSite = Get-PnPSite $taxonomySession = [Microsoft.SharePoint.Client.Taxonomy.TaxonomySession]::GetTaxonomySession($context) $TermStore = $taxonomySession.GetDefaultSiteCollectionTermStore(); $SiteCollectionTermGroup = $TermStore.GetSiteCollectionGroup($CurrentSite, $false) $termsets = $SiteCollectionTermGroup.TermSets $context.Load($taxonomySession) $context.Load($SiteCollectionTermGroup) $context.Load($termsets) $context.Load($TermStore) Invoke-PnPQuery $navigationTermSet = $termsets | Where-Object { $_.Name -eq $termSetName } $context.Load($navigationTermSet) Invoke-PnPQuery $navigationTermSet.IsOpenForTermCreation = $true $navigationTermSet.IsAvailableForTagging = $true $TermStore.CommitAll() Start-Sleep -Seconds 2 Write-Host \u0026#34;Done\u0026#34; -f Green } function Invoke-LoadPnp() { Write-Host \u0026#34;Load Libraries...\u0026#34; -f Yellow -NoNewline $rootpath = $PSScriptRoot $path = Join-Path -Path $rootpath -ChildPath \u0026#34;SharePointPnPPowerShell2019\\3.29.2101.0\\\u0026#34; $sharepointPowershellModulePath = Join-Path -Path $path -ChildPath \u0026#34;SharePointPnPPowerShell2019.psd1\u0026#34; if ($null -eq (Get-Module -Name \u0026#34;SharePointPnPPowerShell2019\u0026#34;)) { Import-Module $sharepointPowershellModulePath -DisableNameChecking Disable-PnPPowerShellTelemetry -Force | Out-Null } #Load SharePoint CSOM Assemblies Add-Type -Path \u0026#34;$path\\Microsoft.SharePoint.Client.dll\u0026#34; Add-Type -Path \u0026#34;$path\\Microsoft.SharePoint.Client.Runtime.dll\u0026#34; Add-Type -Path \u0026#34;$path\\Microsoft.SharePoint.Client.Taxonomy.dll\u0026#34; Add-Type -Path \u0026#34;$path\\Microsoft.SharePoint.Client.Publishing.dll\u0026#34; Write-Host \u0026#34;Done\u0026#34; -f Green } # ------------------------------------------------------------------------------------- # Load PnP and Client Libraries # ------------------------------------------------------------------------------------- Invoke-LoadPnp # ------------------------------------------------------------------------------------- # Connect # ------------------------------------------------------------------------------------- $global:countTerms = 0 Connect-PnPOnline -Url $siteurl -CurrentCredentials $Web = Get-PnPWeb -Includes Title, WebTemplate, Configuration # ------------------------------------------------------------------------------------- # Test Template # ------------------------------------------------------------------------------------- Write-Host \u0026#34;Site $($Web.Title): $($Web.WebTemplate)#$($Web.Configuration)it should be STS#0\u0026#34; if ($Web.WebTemplate -ne \u0026#34;STS\u0026#34; -and $Web.Configuration -ne 0) { Write-Host \u0026#34;Wrong template\u0026#34; -ForegroundColor Red } # ------------------------------------------------------------------------------------- # Setup Features # ------------------------------------------------------------------------------------- Invoke-SetupFeatures # ------------------------------------------------------------------------------------- # Setup Termset # ------------------------------------------------------------------------------------- Invoke-SetupTermSet $termSetName Invoke-UpdateTaxonomyCache # ------------------------------------------------------------------------------------- # Setup Navigation # ------------------------------------------------------------------------------------- Invoke-SetupNavigation $termSetName Invoke-UpdateTaxonomyCache # ------------------------------------------------------------------------------------- # Setup Tagging # ------------------------------------------------------------------------------------- Invoke-EnableTagging $termSetName # ------------------------------------------------------------------------------------- # Create Content # ------------------------------------------------------------------------------------- $Ctx = Get-PnPContext $PublishingWeb = [Microsoft.SharePoint.Client.Publishing.PublishingWeb]::GetPublishingWeb($Ctx, $Ctx.Web) $Ctx.Load($PublishingWeb) $Ctx.ExecuteQuery() $PageLayoutItem = Get-PageLayoutItem \u0026#39;ArticleLeft.aspx\u0026#39; $context = Get-PnPContext $CurrentSite = Get-PnPSite $taxonomySession = [Microsoft.SharePoint.Client.Taxonomy.TaxonomySession]::GetTaxonomySession($context) $termStore = $taxonomySession.GetDefaultSiteCollectionTermStore(); $SiteCollectionTermGroup = $TermStore.GetSiteCollectionGroup($CurrentSite, $false) $termsets = $SiteCollectionTermGroup.TermSets $context.Load($taxonomySession) $context.Load($SiteCollectionTermGroup) $context.Load($termsets) $context.Load($TermStore) Invoke-PnPQuery $termSet = $termsets | Where-Object { $_.Name -eq $termSetName } $context.Load($termSet) Invoke-PnPQuery Invoke-CreateTerms -context $context -PublishingWeb $PublishingWeb -PageLayoutItem $PageLayoutItem -termStore $termStore -termObject $termSet -path \u0026#34;\u0026#34; -level 0 -maxlevel 3 -maxItemsPerLevel 30 -overallMax 3300 Invoke-UpdateTaxonomyCache ","tags":["SharePoint","Powershell"],"section":"post"},{"date":"1634860800","url":"https://conception365.com/post/2021-10-22-jsom-termgroup-add-contributor/","title":"Site termgroup add contributor or manager","summary":"Add site collection term group Managers and Contributors using JSOM On client side for CSOM we have already a solution for adding managers or contributors for term groups. You can have a look here for the original article.\nClientContext clientContext = GetClientContext(); var taxonomySession = TaxonomySession.GetTaxonomySession(clientContext); var termStore = taxonomySession.GetDefaultSiteCollectionTermStore(); var myTermGroup = termStore.Groups.GetByName(\u0026#34;My Custom Terms Group\u0026#34;); //Add Group Managers myTermGroup.AddGroupManager(\u0026#34;i:0#.f|membership|...@tenant.onmicrosoft.com\u0026#34;); //Add Group Contributors myTermGroup.AddContributor(\u0026#34;i:0#.f|membership|...@tenant.onmicrosoft.com\u0026#34;); myTermGroup.AddContributor(\u0026#34;i:0#.f|membership|...@tenant.onmicrosoft.com\u0026#34;); clientContext.Load(myTermGroup, group =\u0026gt; group.GroupManagerPrincipalNames, group =\u0026gt; group.","content":"Add site collection term group Managers and Contributors using JSOM On client side for CSOM we have already a solution for adding managers or contributors for term groups. You can have a look here for the original article.\nClientContext clientContext = GetClientContext(); var taxonomySession = TaxonomySession.GetTaxonomySession(clientContext); var termStore = taxonomySession.GetDefaultSiteCollectionTermStore(); var myTermGroup = termStore.Groups.GetByName(\u0026#34;My Custom Terms Group\u0026#34;); //Add Group Managers myTermGroup.AddGroupManager(\u0026#34;i:0#.f|membership|...@tenant.onmicrosoft.com\u0026#34;); //Add Group Contributors myTermGroup.AddContributor(\u0026#34;i:0#.f|membership|...@tenant.onmicrosoft.com\u0026#34;); myTermGroup.AddContributor(\u0026#34;i:0#.f|membership|...@tenant.onmicrosoft.com\u0026#34;); clientContext.Load(myTermGroup, group =\u0026gt; group.GroupManagerPrincipalNames, group =\u0026gt; group.ContributorPrincipalNames); clientContext.ExecuteQuery(); Console.WriteLine(\u0026#34;Group Managers: \u0026#34;); foreach (var manager in myTermGroup.GroupManagerPrincipalNames) { Console.WriteLine(manager); } Console.WriteLine(\u0026#34;Group Contributors: \u0026#34;); foreach (var contributors in myTermGroup.ContributorPrincipalNames) { Console.WriteLine(contributors); } I extracted the methods for the special case of site collection term group managers and contributors, you can find here a working version with pure typescript. Your class should also have a property for spHttpClient and absoluteWebUrl from pnp js.\n/** * Add manager (creates site term group if not exists, allowed to run multiple times for same user) * @param principalName name of user contoso\\login or Everyone */ public async addSiteGroupManager(principalName: string): Promise\u0026lt;void\u0026gt; { const requestBody = `\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Request xmlns=\u0026#34;http://schemas.microsoft.com/sharepoint/clientquery/2009\u0026#34; SchemaVersion=\u0026#34;15.0.0.0\u0026#34; LibraryVersion=\u0026#34;16.0.0.0\u0026#34; ApplicationName=\u0026#34;Javascript Library\u0026#34;\u0026gt; \u0026lt;Actions\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;1\u0026#34; ObjectPathId=\u0026#34;0\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;2\u0026#34; ObjectPathId=\u0026#34;0\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;4\u0026#34; ObjectPathId=\u0026#34;3\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;5\u0026#34; ObjectPathId=\u0026#34;3\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;7\u0026#34; ObjectPathId=\u0026#34;6\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;9\u0026#34; ObjectPathId=\u0026#34;8\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;11\u0026#34; ObjectPathId=\u0026#34;10\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;12\u0026#34; ObjectPathId=\u0026#34;10\u0026#34; /\u0026gt; \u0026lt;Method Name=\u0026#34;AddGroupManager\u0026#34; Id=\u0026#34;13\u0026#34; ObjectPathId=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter Type=\u0026#34;String\u0026#34;\u0026gt;${principalName}\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;/Actions\u0026gt; \u0026lt;ObjectPaths\u0026gt; \u0026lt;StaticMethod Id=\u0026#34;0\u0026#34; Name=\u0026#34;GetTaxonomySession\u0026#34; TypeId=\u0026#34;{981cbc68-9edc-4f8d-872f-71146fcbb84f}\u0026#34; /\u0026gt; \u0026lt;Method Id=\u0026#34;3\u0026#34; ParentId=\u0026#34;0\u0026#34; Name=\u0026#34;GetDefaultSiteCollectionTermStore\u0026#34; /\u0026gt; \u0026lt;StaticProperty Id=\u0026#34;6\u0026#34; TypeId=\u0026#34;{3747adcd-a3c3-41b9-bfab-4a64dd2f1e0a}\u0026#34; Name=\u0026#34;Current\u0026#34; /\u0026gt; \u0026lt;Property Id=\u0026#34;8\u0026#34; ParentId=\u0026#34;6\u0026#34; Name=\u0026#34;Site\u0026#34; /\u0026gt; \u0026lt;Method Id=\u0026#34;10\u0026#34; ParentId=\u0026#34;3\u0026#34; Name=\u0026#34;GetSiteCollectionGroup\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter ObjectPathId=\u0026#34;8\u0026#34; /\u0026gt; \u0026lt;Parameter Type=\u0026#34;Boolean\u0026#34;\u0026gt;true\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;/ObjectPaths\u0026gt; \u0026lt;/Request\u0026gt;`; return await this.postcsom(requestBody).then((result) =\u0026gt; { if (result[0].ErrorInfo !== null) { throw new Error(JSON.stringify(result[0].ErrorInfo)); } return; }); } /** * Add contributor (creates site term group if not exists, allowed to run multiple times for same user) * @param principalName name of user contoso\\login or Everyone */ public async addSiteGroupContributor(principalName: string): Promise\u0026lt;void\u0026gt; { const requestBody = `\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Request xmlns=\u0026#34;http://schemas.microsoft.com/sharepoint/clientquery/2009\u0026#34; SchemaVersion=\u0026#34;15.0.0.0\u0026#34; LibraryVersion=\u0026#34;16.0.0.0\u0026#34; ApplicationName=\u0026#34;Javascript Library\u0026#34;\u0026gt; \u0026lt;Actions\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;1\u0026#34; ObjectPathId=\u0026#34;0\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;2\u0026#34; ObjectPathId=\u0026#34;0\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;4\u0026#34; ObjectPathId=\u0026#34;3\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;5\u0026#34; ObjectPathId=\u0026#34;3\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;7\u0026#34; ObjectPathId=\u0026#34;6\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;9\u0026#34; ObjectPathId=\u0026#34;8\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;11\u0026#34; ObjectPathId=\u0026#34;10\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;12\u0026#34; ObjectPathId=\u0026#34;10\u0026#34; /\u0026gt; \u0026lt;Method Name=\u0026#34;AddContributor\u0026#34; Id=\u0026#34;13\u0026#34; ObjectPathId=\u0026#34;10\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter Type=\u0026#34;String\u0026#34;\u0026gt;${principalName}\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;/Actions\u0026gt; \u0026lt;ObjectPaths\u0026gt; \u0026lt;StaticMethod Id=\u0026#34;0\u0026#34; Name=\u0026#34;GetTaxonomySession\u0026#34; TypeId=\u0026#34;{981cbc68-9edc-4f8d-872f-71146fcbb84f}\u0026#34; /\u0026gt; \u0026lt;Method Id=\u0026#34;3\u0026#34; ParentId=\u0026#34;0\u0026#34; Name=\u0026#34;GetDefaultSiteCollectionTermStore\u0026#34; /\u0026gt; \u0026lt;StaticProperty Id=\u0026#34;6\u0026#34; TypeId=\u0026#34;{3747adcd-a3c3-41b9-bfab-4a64dd2f1e0a}\u0026#34; Name=\u0026#34;Current\u0026#34; /\u0026gt; \u0026lt;Property Id=\u0026#34;8\u0026#34; ParentId=\u0026#34;6\u0026#34; Name=\u0026#34;Site\u0026#34; /\u0026gt; \u0026lt;Method Id=\u0026#34;10\u0026#34; ParentId=\u0026#34;3\u0026#34; Name=\u0026#34;GetSiteCollectionGroup\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter ObjectPathId=\u0026#34;8\u0026#34; /\u0026gt; \u0026lt;Parameter Type=\u0026#34;Boolean\u0026#34;\u0026gt;true\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;/ObjectPaths\u0026gt; \u0026lt;/Request\u0026gt;`; return await this.postcsom(requestBody).then((result) =\u0026gt; { if (result[0].ErrorInfo !== null) { throw new Error(JSON.stringify(result[0].ErrorInfo)); } return; }); } /** * sends a request to client svc * @param data request data */ // eslint-disable-next-line @typescript-eslint/no-explicit-any  private async postcsom(data: string): Promise\u0026lt;any\u0026gt; { const clientServiceUrl = this.absoluteWebUrl + \u0026#39;/_vti_bin/client.svc/ProcessQuery\u0026#39;; const formDigest = await this.getFormDigest(); const requestHeaders: Headers = new Headers(); requestHeaders.append(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;); requestHeaders.append(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/xml\u0026#39;); requestHeaders.append(\u0026#39;X-RequestDigest\u0026#39;, formDigest); const httpPostOptions: IHttpClientOptions = { headers: requestHeaders, body: data }; const serviceResponse: IResponse = await this.spHttpClient.post(clientServiceUrl,SPHttpClient.configurations.v1, httpPostOptions); const serviceJSONResponse = await serviceResponse.json(); if (serviceResponse.ok) { return serviceJSONResponse; } return null; } /** * digest is needed for post requests */ private async getFormDigest(): Promise\u0026lt;string\u0026gt; { if (this.cachedDigest \u0026amp;\u0026amp; !this.isDigestDateInvalid()) return this.cachedDigest; this.cachedDigestDate = new Date(); const contextInfoUrl = this.absoluteWebUrl + \u0026#39;/_api/contextinfo\u0026#39;; const requestHeaders: Headers = new Headers(); requestHeaders.append(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;); requestHeaders.append(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/xml\u0026#39;); const httpPostOptions: IHttpClientOptions = { headers: requestHeaders }; const contextInfoResponse: IResponse = await this.spHttpClient.post(contextInfoUrl, httpPostOptions); const contextInfoJsonResponse = await contextInfoResponse.json(); const formDigest: string = contextInfoJsonResponse.FormDigestValue; this.cachedDigest = formDigest; return formDigest; } private isDigestDateInvalid(): boolean { const today = new Date().getTime(); const cachedtime = this.cachedDigestDate.getTime(); const difference = Math.abs(cachedtime - today); const seconds = (difference / 1000) % 60; return seconds \u0026gt; 60; } The easy usage is:\naddSiteGroupContributor(\u0026#39;Everyone\u0026#39;) ","tags":["SharePoint","SPFX","JSOM","Javascript"],"section":"post"},{"date":"1630368000","url":"https://conception365.com/post/2021-08-31-spfx-showcase-mysite/","title":"SPFX Showcase - MySite","summary":"Modern Mysite on SharePoint 2019 I like to share some ideas from current project to have a modern MySite on a SharePoint 2019. It is completely created by a SPFX solution with multiple webparts. Unfortunately it is a customer project and i can not share any code.\nIt comes with three webparts:\n  Userprofile The user profile webpart shows your user profile information together with your profile picture in smart grouped categories.","content":"Modern Mysite on SharePoint 2019 I like to share some ideas from current project to have a modern MySite on a SharePoint 2019. It is completely created by a SPFX solution with multiple webparts. Unfortunately it is a customer project and i can not share any code.\nIt comes with three webparts:\n  Userprofile The user profile webpart shows your user profile information together with your profile picture in smart grouped categories. You also have your organization chart displayed. Of course if you open a user profile for another user it shows his profile.\nYou can edit and upload your profile picture with some nice cropping function.  Also you have a complete profile editor, every property is read from user profile service.  The webpart settings allow you to make some customization.  For example to define your grouping.  News The news webpart shows the latest activities. In all view everything is grouped together with the modern Sharepoint news.  Following The following webpart shows your followed content. you see all the people, documents and sites.  Technical hints You don\u0026rsquo;t have to replace your MySite host, we just use a extra site collection with modern teamsite template. All you have to do is, to add some rewrite rules to your MySite webapplication. With permanent redirect, the user has a smart experience.\nI hope a could give you some inspiration.\n","tags":["SharePoint","SP2019","MySite"],"section":"post"},{"date":"1628812800","url":"https://conception365.com/post/2021-08-13-spfx-2019-pnpm/","title":"SPFX 2019 - speed up npm performance","summary":"Problem For current sharepoint projects we have huge node_modules folders. With every new project we have to download everything again. I started to look for a better solution and found pnpm.\nSolution pnpm  is a complete custom package manager designed for better performance, but compatible with npm. Instead of heaving multiple packages it uses symlinks and reuses packages. They published a speed comparison, in some tests it is pretty fast, especial if you already have some projects.","content":"Problem For current sharepoint projects we have huge node_modules folders. With every new project we have to download everything again. I started to look for a better solution and found pnpm.\nSolution pnpm  is a complete custom package manager designed for better performance, but compatible with npm. Instead of heaving multiple packages it uses symlinks and reuses packages. They published a speed comparison, in some tests it is pretty fast, especial if you already have some projects.\n  So next steps are to prepare our existing solution for showcase.\nCleanup old node_modules Fastest way to cleanup your node_modules folder is via npm rimraf. Install this global:\nnpm install rimraf -g Now you can easy clean your folder:\nPS C:\\daten\\git\\spfx-2019-solution\\spfx-2019\u0026gt; rimraf node_modules Install pnpm With npm we install a global version of pnpm. We need version 5 because we have node v12 for our sharepoint 2019 projects.\nnpm i pnpm@5.18.9 -g Next step is to give pnpm a better storage folder. Edit your npm config.\nnpm config edit You can set your folder here:\nstore-dir=C:\\Daten\\pnpm\\store optional=false No we reinstall our packages with pnpm. We use the \u0026ndash;shamefully-hoist because we need to recover our structure.\n By default, pnpm creates a semistrict node_modules, meaning dependencies have access to undeclared dependencies but modules outside of node_modules do not. With this layout, most of the packages in the ecosystem work with no issues. However, if some tooling only works when the hoisted dependencies are in the root of node_modules, you can set this to true to hoist them for you.\n PS C:\\daten\\git\\spfx-2019-solution\\spfx-2019\u0026gt; pnpm install --shamefully-hoist WARN @microsoft/sp-build-web \u0026gt; @microsoft/sp-build-common \u0026gt; @microsoft/sp-tslint-rules: tslint-microsoft-contrib@5.0.3 requires a peer of typescript@^2.1.0 but version 3.6.4 was installed.pt/3.6.4: 6.22 MB/8.2 MB Packages: +1580 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Packages are hard linked from the content-addressable store to the virtual store. Content-addressable store is at: C:\\daten\\pnpm\\store\\v3 Virtual store is at: node_modules/.pnpm Downloading registry.npmjs.org/typescript/3.6.4: 8.2 MB/8.2 MB, done Downloading registry.npmjs.org/office-ui-fabric-react/5.21.0: 7.33 MB/7.33 MB, done Progress: resolved 1599, reused 0, downloaded 1599, added 1580, done WARN Failed to find \u0026#34;/watchpack-chokidar2/2.0.1\u0026#34; in lockfile during hoisting. Next aliases will not be hoisted: watchpack-chokidar2 WARN Failed to find \u0026#34;/fsevents/1.2.13\u0026#34; in lockfile during hoisting. Next aliases will not be hoisted: fsevents WARN Failed to find \u0026#34;/uglify-to-browserify/1.0.2\u0026#34; in lockfile during hoisting. Next aliases will not be hoisted: uglify-to-browserify node_modules/.pnpm/deasync@0.1.22/node_modules/deasync: Running install script, done in 1.7s node_modules/.pnpm/core-js@2.6.12/node_modules/core-js: Running postinstall script, done in 876ms node_modules/.pnpm/ejs@2.7.4/node_modules/ejs: Running postinstall script, done in 912ms node_modules/.pnpm/@microsoft/sp-loader@1.4.1/node_modules/@microsoft/sp-loader: Running install script, done in 1s node_modules/.pnpm/node-sass@4.14.1/node_modules/node-sass: Running install script, done in 2.4s node_modules/.pnpm/spawn-sync@1.0.15/node_modules/spawn-sync: Running postinstall script, done in 811ms node_modules/.pnpm/phantomjs-prebuilt@2.1.16/node_modules/phantomjs-prebuilt: Running install script, done in 6.9s node_modules/.pnpm/node-sass@4.14.1/node_modules/node-sass: Running postinstall script, done in 1.9s node_modules/.pnpm/uglifyjs-webpack-plugin@0.4.6_webpack@3.6.0/node_modules/uglifyjs-webpack-plugin: Running postinstall script, done in 322ms Cannot link binary \u0026#39;jest\u0026#39; of \u0026#39;jest-cli\u0026#39; to \u0026#39;C:\\daten\\git\\spfx-2019-solution\\spfx-2019\\node_modules\\.pnpm\\@microsoft\\gulp-core-build@3.2.7\\node_modules\\@microsoft\\gulp-core-build\\node_modules\\.bin\u0026#39;: binary of \u0026#39;jest\u0026#39; is already linked dependencies: + @custom/spfx-2019-lib 1.0.0 \u0026lt;- ..\\spfx-2019-lib + @microsoft/decorators 1.4.1 (1.12.1 is available) + @microsoft/sp-application-base 1.4.1 (1.12.1 is available) + @microsoft/sp-core-library 1.4.1 (1.12.1 is available) + @microsoft/sp-dialog 1.4.1 (1.12.1 is available) + @microsoft/sp-lodash-subset 1.4.1 (1.12.1 is available) + @microsoft/sp-office-ui-fabric-core 1.4.1 (1.12.1 is available) + @microsoft/sp-webpart-base 1.4.1 (1.12.1 is available) + react 15.6.2 (17.0.2 is available) + react-dom 15.6.2 (17.0.2 is available) devDependencies: + @microsoft/generator-sharepoint 1.9.1 (1.12.1 is available) + @microsoft/sp-build-web 1.4.1 (1.12.1 is available) + @microsoft/sp-module-interfaces 1.4.1 (1.12.1 is available) + @microsoft/sp-webpart-workbench 1.4.1 (1.12.1 is available) + @types/es6-promise 0.0.33 (3.3.0 is available) + @types/microsoft-ajax 0.0.33 (0.0.37 is available) + @types/react 15.6.6 (17.0.17 is available) + @types/react-dom 15.5.6 (17.0.9 is available) + @types/sharepoint 2016.1.2 (2016.1.10 is available) + ajv 5.2.5 (8.6.2 is available) + gulp 3.9.1 (4.0.2 is available) + typescript 3.6.4 (4.3.5 is available) Thats all! We can add finally a preinstall to our package.json to prevent from using npm again.\n\u0026ldquo;preinstall\u0026rdquo;: \u0026ldquo;npx only-allow pnpm\u0026rdquo;\nBonus create spfx packages Our yeoman generator for sharepoint also supports this package manager:\nyo @microsoft/sharepoint --package-manager pnpm ","tags":["SharePoint","SP2019","pnpm"],"section":"post"},{"date":"1626998400","url":"https://conception365.com/post/2021-07-23-spse-first-review/","title":"SharePoint Server Subscription Edition - First Review","summary":"New SharePoint OnPremise Version Four days ago a new SharePoint OnPremise version is released for preview. It is called SharePoint Server Subscription Edition and comes with some promising headlines:\n Today we’re excited to open the window to our vision, strategy, and future for SharePoint and provide a first look at the most recent developments with SharePoint Server.\n  We designed SharePoint Server SE around the core principles of: Always up to date, Secure and reliable, Designed for you","content":"New SharePoint OnPremise Version Four days ago a new SharePoint OnPremise version is released for preview. It is called SharePoint Server Subscription Edition and comes with some promising headlines:\n Today we’re excited to open the window to our vision, strategy, and future for SharePoint and provide a first look at the most recent developments with SharePoint Server.\n  We designed SharePoint Server SE around the core principles of: Always up to date, Secure and reliable, Designed for you\n Ok. It take this, open blog post here for more details!\nInstallation I did a small installation on a virtual machine and created a single server farm. Not a big deal, everything straightforward.\nImpressions So after checking, we get the version 16.0.14131.20314, yes thats what we saw on installation files already.\n  Teamsite Looks very the same like SP 2019, think there are some really small updates, nothing big:\n SharePoint Server Subscription Edition includes numerous accessibility improvements across the modern UX to ensure that all users can be productive with SharePoint.\n   Search  Support for returning list content in modern results page.\n   Compared to the existing one in SharePoint 2019.\n  Document thumbnails  SharePoint Server Subscription Edition can render thumbnails of files in the Tiles view of document libraries and picture libraries. SharePoint will render thumbnails of popular image file formats such as PNG, JPEG, GIF, and more. And if you\u0026rsquo;ve linked your SharePoint Server farm to an Office Online Server farm, SharePoint will also be able to render thumbnails of popular document formats such as PDFs, Word documents, PowerPoint documents, and Rich Text Files.\n   Summary First that explains why it is not called SharePoint 2022, because SharePoint Server Subscription Edition is basically SharePoint 2019. Some really small improvements but no big steps. Someone called it a managed version of SP 2019, that is for me a good description.\nIn general i still miss the following features:\n Latest SPFX Version HubSites Updates to Modern UI  So i think we have to wait for further communication from Microsoft!\n","tags":["SharePoint","SharePointSE"],"section":"post"},{"date":"1625184000","url":"https://conception365.com/post/2021-07-02-spfx-publish-classic-listforms/","title":"Javascript - Publish classic list form webparts","summary":"Problem For classic SharePoint 2019 libraries you still need your EditForm.aspx and DispForm.aspx to edit your properties. If you like to make any changes, create another form page or repair it by code, it is a little bit more complicated. Most time you try to edit the \u0026ldquo;DefaultEditFormUrl\u0026rdquo; property of your list. If you try to change the \u0026ldquo;DefaultEditFormUrl\u0026rdquo; property it leads some time to the following error:\nUnable to find an SPForm matching URL.","content":"Problem For classic SharePoint 2019 libraries you still need your EditForm.aspx and DispForm.aspx to edit your properties. If you like to make any changes, create another form page or repair it by code, it is a little bit more complicated. Most time you try to edit the \u0026ldquo;DefaultEditFormUrl\u0026rdquo; property of your list. If you try to change the \u0026ldquo;DefaultEditFormUrl\u0026rdquo; property it leads some time to the following error:\nUnable to find an SPForm matching URL... The reason is, sharepoint evaluates your target url and try to find the form on the page. So you have also to upload the list form webpart.\nSolution Here i show some helpers to realise this with javascript code. Most samples on internet are powershell, but doing this in a SPFX solution it is also very smart. We use here some help from pnp js (https://pnp.github.io/pnpjs/) framework. You can download the content of the aspx file from a existing library by open your folder in internet explorer and copy the file.\nUpload your editform.aspx const folderUrl = \u0026#39;/sites/sitecollection/library/\u0026#39;; const dispFormUrl = `${folderUrl}/Forms/EditForm.aspx`; const content = `..........`; //replace your content await this.uploadFile(folderUrl, dispFormUrl, content); /** * Upload a file from a library * * @param folderUrl relative path of a library or the folder in a library * @param fileUrl new relative url of the file * @param content content of the file */ public async uploadFile(folderUrl: string, fileUrl: string, content: Blob | ArrayBuffer | string): Promise\u0026lt;void\u0026gt; { const props: IAddUsingPathProps = { Overwrite: true }; await sp.web.getFolderByServerRelativeUrl(folderUrl).files.addUsingPath(fileUrl, content, props); } Import Webparts You need to import the list webpart, don\u0026rsquo;t forget to set the listid. Your class should also have a property for spHttpClient and absoluteWebUrl from pnp js.\nconst listInfoId:string = \u0026#39;xxxxx-xx-xxxx-..\u0026#39;; const editwebpartxml = `\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;WebPart xmlns:xsd=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2\u0026#34;\u0026gt; \u0026lt;Title /\u0026gt; \u0026lt;FrameType\u0026gt;Default\u0026lt;/FrameType\u0026gt; \u0026lt;Description /\u0026gt; \u0026lt;IsIncluded\u0026gt;true\u0026lt;/IsIncluded\u0026gt; \u0026lt;ZoneID\u0026gt;Main\u0026lt;/ZoneID\u0026gt; \u0026lt;PartOrder\u0026gt;1\u0026lt;/PartOrder\u0026gt; \u0026lt;FrameState\u0026gt;Normal\u0026lt;/FrameState\u0026gt; \u0026lt;Height /\u0026gt; \u0026lt;Width /\u0026gt; \u0026lt;AllowRemove\u0026gt;true\u0026lt;/AllowRemove\u0026gt; \u0026lt;AllowZoneChange\u0026gt;true\u0026lt;/AllowZoneChange\u0026gt; \u0026lt;AllowMinimize\u0026gt;true\u0026lt;/AllowMinimize\u0026gt; \u0026lt;AllowConnect\u0026gt;true\u0026lt;/AllowConnect\u0026gt; \u0026lt;AllowEdit\u0026gt;true\u0026lt;/AllowEdit\u0026gt; \u0026lt;AllowHide\u0026gt;true\u0026lt;/AllowHide\u0026gt; \u0026lt;IsVisible\u0026gt;true\u0026lt;/IsVisible\u0026gt; \u0026lt;DetailLink /\u0026gt; \u0026lt;HelpLink /\u0026gt; \u0026lt;HelpMode\u0026gt;Modeless\u0026lt;/HelpMode\u0026gt; \u0026lt;Dir\u0026gt;Default\u0026lt;/Dir\u0026gt; \u0026lt;PartImageSmall /\u0026gt; \u0026lt;MissingAssembly\u0026gt;Dieses Webpart kann nicht importiert werden.\u0026lt;/MissingAssembly\u0026gt; \u0026lt;PartImageLarge /\u0026gt; \u0026lt;IsIncludedFilter /\u0026gt; \u0026lt;Assembly\u0026gt;Microsoft.SharePoint, Version=16.0.0.0, Culture=neutral, PublicKeyToken=71e9bce111e9429c\u0026lt;/Assembly\u0026gt; \u0026lt;TypeName\u0026gt;Microsoft.SharePoint.WebPartPages.ListFormWebPart\u0026lt;/TypeName\u0026gt; \u0026lt;ListName xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;{${listInfoId}}\u0026lt;/ListName\u0026gt; \u0026lt;ListId xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;${listInfoId}\u0026lt;/ListId\u0026gt; \u0026lt;PageType xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;PAGE_EDITFORM\u0026lt;/PageType\u0026gt; \u0026lt;FormType xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;6\u0026lt;/FormType\u0026gt; \u0026lt;ControlMode xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;Edit\u0026lt;/ControlMode\u0026gt; \u0026lt;ViewFlag xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;1048576\u0026lt;/ViewFlag\u0026gt; \u0026lt;ViewFlags xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;Default\u0026lt;/ViewFlags\u0026gt; \u0026lt;ListItemId xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;0\u0026lt;/ListItemId\u0026gt; \u0026lt;/WebPart\u0026gt;`; const displaywebpartxml = `\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;WebPart xmlns:xsd=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2\u0026#34;\u0026gt; \u0026lt;Title /\u0026gt; \u0026lt;FrameType\u0026gt;Default\u0026lt;/FrameType\u0026gt; \u0026lt;Description /\u0026gt; \u0026lt;IsIncluded\u0026gt;true\u0026lt;/IsIncluded\u0026gt; \u0026lt;ZoneID\u0026gt;Main\u0026lt;/ZoneID\u0026gt; \u0026lt;PartOrder\u0026gt;1\u0026lt;/PartOrder\u0026gt; \u0026lt;FrameState\u0026gt;Normal\u0026lt;/FrameState\u0026gt; \u0026lt;Height /\u0026gt; \u0026lt;Width /\u0026gt; \u0026lt;AllowRemove\u0026gt;true\u0026lt;/AllowRemove\u0026gt; \u0026lt;AllowZoneChange\u0026gt;true\u0026lt;/AllowZoneChange\u0026gt; \u0026lt;AllowMinimize\u0026gt;true\u0026lt;/AllowMinimize\u0026gt; \u0026lt;AllowConnect\u0026gt;true\u0026lt;/AllowConnect\u0026gt; \u0026lt;AllowEdit\u0026gt;true\u0026lt;/AllowEdit\u0026gt; \u0026lt;AllowHide\u0026gt;true\u0026lt;/AllowHide\u0026gt; \u0026lt;IsVisible\u0026gt;true\u0026lt;/IsVisible\u0026gt; \u0026lt;DetailLink /\u0026gt; \u0026lt;HelpLink /\u0026gt; \u0026lt;HelpMode\u0026gt;Modeless\u0026lt;/HelpMode\u0026gt; \u0026lt;Dir\u0026gt;Default\u0026lt;/Dir\u0026gt; \u0026lt;PartImageSmall /\u0026gt; \u0026lt;MissingAssembly\u0026gt;Dieses Webpart kann nicht importiert werden.\u0026lt;/MissingAssembly\u0026gt; \u0026lt;PartImageLarge /\u0026gt; \u0026lt;IsIncludedFilter /\u0026gt; \u0026lt;Assembly\u0026gt;Microsoft.SharePoint, Version=16.0.0.0, Culture=neutral, PublicKeyToken=71e9bce111e9429c\u0026lt;/Assembly\u0026gt; \u0026lt;TypeName\u0026gt;Microsoft.SharePoint.WebPartPages.ListFormWebPart\u0026lt;/TypeName\u0026gt; \u0026lt;ListName xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;{${listInfoId}}\u0026lt;/ListName\u0026gt; \u0026lt;ListId xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;${listInfoId}\u0026lt;/ListId\u0026gt; \u0026lt;PageType xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;PAGE_DISPLAYFORM\u0026lt;/PageType\u0026gt; \u0026lt;FormType xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;4\u0026lt;/FormType\u0026gt; \u0026lt;ControlMode xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;Display\u0026lt;/ControlMode\u0026gt; \u0026lt;ViewFlag xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;1048576\u0026lt;/ViewFlag\u0026gt; \u0026lt;ViewFlags xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;Default\u0026lt;/ViewFlags\u0026gt; \u0026lt;ListItemId xmlns=\u0026#34;http://schemas.microsoft.com/WebPart/v2/ListForm\u0026#34;\u0026gt;0\u0026lt;/ListItemId\u0026gt; \u0026lt;/WebPart\u0026gt;`; await this.importClassicPageWebpart(dispFormUrl, \u0026#39;Main\u0026#39;, 1, displaywebpartxml); await this.importClassicPageWebpart(editFormUrl, \u0026#39;Main\u0026#39;, 1, editwebpartxml); /** * Imports webpart on classic page * @param pageUrl * @param zone Main * @param order 1 * @param webpartxml * @returns */ public async importClassicPageWebpart( pageUrl: string, zone: string, order: number, webpartxml: string ): Promise\u0026lt;void\u0026gt; { const webid = (await sp.web.get()).Id; const siteid = (await sp.site.get()).Id; webpartxml = this.encodeXml(webpartxml); const requestBody = `\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Request xmlns=\u0026#34;http://schemas.microsoft.com/sharepoint/clientquery/2009\u0026#34; SchemaVersion=\u0026#34;15.0.0.0\u0026#34; LibraryVersion=\u0026#34;16.0.0.0\u0026#34; ApplicationName=\u0026#34;Javascript Library\u0026#34;\u0026gt; \u0026lt;Actions\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;41\u0026#34; ObjectPathId=\u0026#34;40\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;43\u0026#34; ObjectPathId=\u0026#34;42\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;44\u0026#34; ObjectPathId=\u0026#34;42\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;46\u0026#34; ObjectPathId=\u0026#34;45\u0026#34; /\u0026gt; \u0026lt;ObjectPath Id=\u0026#34;48\u0026#34; ObjectPathId=\u0026#34;47\u0026#34; /\u0026gt; \u0026lt;ObjectIdentityQuery Id=\u0026#34;49\u0026#34; ObjectPathId=\u0026#34;47\u0026#34; /\u0026gt; \u0026lt;Query Id=\u0026#34;50\u0026#34; ObjectPathId=\u0026#34;45\u0026#34;\u0026gt; \u0026lt;Query SelectAllProperties=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;Properties /\u0026gt; \u0026lt;/Query\u0026gt; \u0026lt;/Query\u0026gt; \u0026lt;/Actions\u0026gt; \u0026lt;ObjectPaths\u0026gt; \u0026lt;Method Id=\u0026#34;40\u0026#34; ParentId=\u0026#34;28\u0026#34; Name=\u0026#34;GetLimitedWebPartManager\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter Type=\u0026#34;Number\u0026#34;\u0026gt;1\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;Method Id=\u0026#34;42\u0026#34; ParentId=\u0026#34;40\u0026#34; Name=\u0026#34;ImportWebPart\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter Type=\u0026#34;String\u0026#34;\u0026gt;${webpartxml}\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;Property Id=\u0026#34;45\u0026#34; ParentId=\u0026#34;42\u0026#34; Name=\u0026#34;WebPart\u0026#34; /\u0026gt; \u0026lt;Method Id=\u0026#34;47\u0026#34; ParentId=\u0026#34;40\u0026#34; Name=\u0026#34;AddWebPart\u0026#34;\u0026gt; \u0026lt;Parameters\u0026gt; \u0026lt;Parameter ObjectPathId=\u0026#34;45\u0026#34; /\u0026gt; \u0026lt;Parameter Type=\u0026#34;String\u0026#34;\u0026gt;${zone}\u0026lt;/Parameter\u0026gt; \u0026lt;Parameter Type=\u0026#34;Number\u0026#34;\u0026gt;${order}\u0026lt;/Parameter\u0026gt; \u0026lt;/Parameters\u0026gt; \u0026lt;/Method\u0026gt; \u0026lt;Identity Id=\u0026#34;28\u0026#34; Name=\u0026#34;82d7c99e-f015-0000-6402-fdbb9f2aa54d|740c6a0b-85e2-48a0-a494-e0f1759d4aa7:site:${siteid}:web:${webid}:file:${pageUrl}\u0026#34; /\u0026gt; \u0026lt;/ObjectPaths\u0026gt; \u0026lt;/Request\u0026gt;`; return await this.postcsom(requestBody).then((result) =\u0026gt; { if (result[0].ErrorInfo !== null) { throw new Error(JSON.stringify(result[0].ErrorInfo)); } return; }); } /** * xml encodes a string * @param str * @returns */ private encodeXml(str: string): string { const xml_special_to_escaped_one_map = { \u0026#39;\u0026amp;\u0026#39;: \u0026#39;\u0026amp;amp;\u0026#39;, \u0026#39;\u0026#34;\u0026#39;: \u0026#39;\u0026amp;quot;\u0026#39;, \u0026#39;\u0026lt;\u0026#39;: \u0026#39;\u0026amp;lt;\u0026#39;, \u0026#39;\u0026gt;\u0026#39;: \u0026#39;\u0026amp;gt;\u0026#39; }; return str.replace(/([\\\u0026amp;\u0026#34;\u0026lt;\u0026gt;])/g, function (str, item) { return xml_special_to_escaped_one_map[item]; }); } /** * sends a request to client svc * @param data request data */ private async postcsom(data: string): Promise\u0026lt;any\u0026gt; { const clientServiceUrl = this.absoluteWebUrl + \u0026#39;/_vti_bin/client.svc/ProcessQuery\u0026#39;; const formDigest = await this.getFormDigest(); const requestHeaders: Headers = new Headers(); requestHeaders.append(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;); requestHeaders.append(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/xml\u0026#39;); requestHeaders.append(\u0026#39;X-RequestDigest\u0026#39;, formDigest); const httpPostOptions: IHttpClientOptions = { headers: requestHeaders, body: data }; const serviceResponse: IResponse = await this.spHttpClient.post(clientServiceUrl,SPHttpClient.configurations.v1, httpPostOptions); const serviceJSONResponse = await serviceResponse.json(); if (serviceResponse.ok) { return serviceJSONResponse; } return null; } /** * digest is needed for post requests */ private async getFormDigest(): Promise\u0026lt;string\u0026gt; { const contextInfoUrl = this.absoluteWebUrl + \u0026#39;/_api/contextinfo\u0026#39;; const requestHeaders: Headers = new Headers(); requestHeaders.append(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;); requestHeaders.append(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/xml\u0026#39;); const httpPostOptions: IHttpClientOptions = { headers: requestHeaders }; const contextInfoResponse: IResponse = await this.spHttpClient.post(contextInfoUrl, httpPostOptions); const contextInfoJsonResponse = await contextInfoResponse.json(); const formDigest: string = contextInfoJsonResponse.FormDigestValue; return formDigest; } Update DefaultDisplayFormUrl Finally you can update your list form without errors.\nawait this.updateList(listTitle, { DefaultDisplayFormUrl: dispFormUrl, DefaultEditFormUrl: editFormUrl, ContentTypesEnabled: false }); /** * Updates List Properties * @param listTitle * @param properties of type IListInfo possible */ public async updateList(listTitle: string, properties: Record\u0026lt;string, unknown\u0026gt;): Promise\u0026lt;void\u0026gt; { await sp.web.lists.getByTitle(listTitle).update(properties); } By the way, you see also a easy method how to interact with jsom api, without having the complete api included.\n","tags":["SPFX","SP2019"],"section":"post"},{"date":"1621382400","url":"https://conception365.com/post/2021-05-19-spfx-2019-custominstaller/","title":"SPFX 2019 Custom Installer","summary":"What we create In SharePoint SPFX solution development you have most time the requirement to do some installation tasks. You have multiple solutions for that problem. First - most content can be deployed via XML manifest files to your website. This helps you with the most basic stuff, but if you like to do some more modifications, for example set special permissions on lists or deploy webparts to your page, it have to be done extra.","content":"What we create In SharePoint SPFX solution development you have most time the requirement to do some installation tasks. You have multiple solutions for that problem. First - most content can be deployed via XML manifest files to your website. This helps you with the most basic stuff, but if you like to do some more modifications, for example set special permissions on lists or deploy webparts to your page, it have to be done extra.\nTo reach this advanced installation we use an application customizer. This customizer is running once and just executed directly after install your app. Inside the customizer you can run further code to perform every action you like.\nHow it looks It is starting with the basic app installation. So select your app from \u0026ldquo;Add an app\u0026rdquo; dialog.\n  After finished installation, refresh your page and you will get a short install notice. You could also set up some configuration wizard or deny the installation for some reason.\n  After successful installation you will get a dialog message and everything is done.\nHow it is build You start with an default application customizer. You can add this via yeoman generator.\nOn the onInit function we call our install and remove the customizer after successful installation.\npublic async onInit(): Promise\u0026lt;void\u0026gt; { Log.info(LOG_SOURCE, `Initialized ${strings.Title}`); //do this only as site admin  if (this.context.pageContext.legacyPageContext.isSiteAdmin) { try { //do installation  await this.install(); //if everything fine remove customizer  await this.removeCustomizer(this.componentId); Log.info(LOG_SOURCE, \u0026#34;Removed customizer\u0026#34;, this.context.serviceScope); await Dialog.alert(`Success. Refresh page!`); } catch (err) { console.log(err); Log.error(LOG_SOURCE, err, this.context.serviceScope); await Dialog.alert(`Error`); } } return Promise.resolve(); } The install function contains all your install logic you need. Be sure that you do not forget to handle errors and maybe redo the installation until everything is fine.\nprivate async install(): Promise\u0026lt;void\u0026gt; { await Dialog.alert(`Do some install stuff.`); return; } To finish our installation we need to remove our customizer from the custom actions.\nprotected removeCustomizer(componentId: string) { try { this._getdigest().then((digrestJson) =\u0026gt; { console.log(digrestJson); const digest = digrestJson.FormDigestValue; const headers = { \u0026#34;X-RequestDigest\u0026#34;: digest, \u0026#34;content-type\u0026#34;: \u0026#34;application/json;odata=verbose\u0026#34;, }; const spOpts: ISPHttpClientOptions = {}; this.context.spHttpClient .get( this.context.pageContext.web.absoluteUrl + `/_api/web/UserCustomActions`, SPHttpClient.configurations.v1, spOpts ) .then((response: SPHttpClientResponse) =\u0026gt; { response.json().then((responseJSON: any) =\u0026gt; { console.log(responseJSON); responseJSON.value.forEach((element) =\u0026gt; { //Match custom action  if (element.ClientSideComponentId == componentId) { //found custom action, call REST API to delete object  this.context.spHttpClient .post( this.context.pageContext.web.absoluteUrl + \u0026#34;/_api/web/UserCustomActions(@v0)/deleteObject()?@v0=guid\u0026#39;\u0026#34; + element.Id + \u0026#34;\u0026#39;\u0026#34;, SPHttpClient.configurations.v1, spOpts ) .then((response: SPHttpClientResponse) =\u0026gt; { console.log( \u0026#34;I think I just deleted a custom action via REST API---\u0026#34; ); }); } }); }); }); }); } catch (error) { console.error(error); } } To get everything running you also need to setup your package-solution with the feature and add your customizer as custom action. Hint: This works only for apps installed on a website.\n\u0026#34;skipFeatureDeployment\u0026#34;: false, \u0026#34;features\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Application Extension - Deployment of custom action.\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Deploys a custom action with ClientSideComponentId association\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;a4b2f6ab-5e1b-4b6c-aa40-f4a708929633\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0.0\u0026#34;, \u0026#34;assets\u0026#34;: { \u0026#34;elementManifests\u0026#34;: [ \u0026#34;elements.xml\u0026#34;, \u0026#34;CustomInstallerApplicationCustomizer.xml\u0026#34; ] } } ] To provision your custom action you add the CustomInstallerApplicationCustomizer.xml on the assets folder.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;Elements xmlns=\u0026#34;http://schemas.microsoft.com/sharepoint/\u0026#34;\u0026gt; \u0026lt;CustomAction Title=\u0026#34;CustomInstallerApplicationCustomizer\u0026#34; Location=\u0026#34;ClientSideExtension.ApplicationCustomizer\u0026#34; ClientSideComponentId=\u0026#34;6cc39d9d-d730-4352-8212-7108749e04f9\u0026#34;\u0026gt; \u0026lt;/CustomAction\u0026gt; \u0026lt;/Elements\u0026gt; Thats everything to go! Smart hint, it deploys automatically a feature (like shown in solution config). You can manual deactivate this feature on your web settings and after reactivation the installer runs again.\nFull code here.\n","tags":["SPFX","SP2019"],"section":"post"},{"date":"1621382400","url":"https://conception365.com/post/2021-05-19-spfx-2019-unexpected-token/","title":"SPFX 2019 Unexpected token - Uglify","summary":"Problem If you are using some third party libraries on SPFX 2019 there can be a problem with your typescript language set. Everything works fine in development, but on production build you get an error message like this one:\nSyntaxError: Unexpected token: name (xxxxxx) from Uglify plugin The problem ist, that third party library uses ES6 code and UglifyJS ist not able to compile ES6.\nSolution UglifyJS does not support this compile, so we can go for TerserPlugin.","content":"Problem If you are using some third party libraries on SPFX 2019 there can be a problem with your typescript language set. Everything works fine in development, but on production build you get an error message like this one:\nSyntaxError: Unexpected token: name (xxxxxx) from Uglify plugin The problem ist, that third party library uses ES6 code and UglifyJS ist not able to compile ES6.\nSolution UglifyJS does not support this compile, so we can go for TerserPlugin. (Source) In latest SPFX 1.12.1, Microsoft also don\u0026rsquo;t use UglifyJS anymore, it is @Microsoft/Rush-Stack-Compiler-x-x.\nFirst add this package to your devDependencies in package.json:\n\u0026#34;terser-webpack-plugin-legacy\u0026#34;: \u0026#34;1.2.3\u0026#34; Second is to change your build configuration in gulpfile.js.\nconst TerserPlugin = require(\u0026#39;terser-webpack-plugin-legacy\u0026#39;); ... build.configureWebpack.mergeConfig({ additionalConfiguration: (generatedConfiguration) =\u0026gt; { // Replace the UglifyJS plugin with Terser, so that this will work with ES6  generatedConfiguration.plugins.forEach((plugin, i) =\u0026gt; { if (plugin.options \u0026amp;\u0026amp; plugin.options.mangle) { generatedConfiguration.plugins[i] = new TerserPlugin({ test: /\\.(js|vue)(\\?.*)?$/i }) } }) return generatedConfiguration; } }); build.initialize(require(\u0026#39;gulp\u0026#39;)); For us everything worked fine afterwards.\n","tags":["SPFX","SP2019"],"section":"post"},{"date":"1620259200","url":"https://conception365.com/post/2021-05-06-import-export-userprofilelinks/","title":"Migrate User Profile My Links","summary":"Problem SharePoint users can store favorite links directly inside the mysite. If you like to migrate to another SharePoint version or different server maybe you like to transfer these links without copy the database. In general these links are stored in the ProfileDB of your server. There is a smart article about this from Vinods source.\nHere a small sample, where you can edit links:\n  source\nSolution I wrote a improved script to import and export the data via xml.","content":"Problem SharePoint users can store favorite links directly inside the mysite. If you like to migrate to another SharePoint version or different server maybe you like to transfer these links without copy the database. In general these links are stored in the ProfileDB of your server. There is a smart article about this from Vinods source.\nHere a small sample, where you can edit links:\n  source\nSolution I wrote a improved script to import and export the data via xml. For export we use the profile manager to get the data and collect for every user all links.\n$profileManager = Get-UserProfileManager $profiles = $profileManager.GetEnumerator() $all = $profileManager.Count $collection = @() $num = 0 foreach ($profile in $profiles) { $userProfile = $profileManager.GetUserProfile($profile.AccountName); foreach ($link in $userProfile.QuickLinks.GetItems() ) { $myLink = [PSCustomObject]@{ AccountName = $profile.AccountName Title = $link.Title Url = $link.Url Group  = $link.Group  PrivacyLevel = $link.PrivacyLevel ID = $link.ID } $collection += $myLink } $num ++ if (0 -eq ($num % 1000)) { Write-Host \u0026#34;User profiles collected $num / $all\u0026#34; -ForegroundColor Gray } } On the import site we need only recreate this link\n$profileManager = Get-UserProfileManager $userProfile = $profileManager.GetUserProfile($link.AccountName); $userProfile.QuickLinks.Create($link.Title, $link.Url, \u0026#34;UserSpecified\u0026#34;, $link.Group, $link.PrivacyLevel) | Out-Null Full script:\nAdd-PSSnapin Microsoft.SharePoint.PowerShell -ErrorAction SilentlyContinue Function Export-UserProfileLinks($filePath) { Try { Write-Host \u0026#34;Enter Export-UserProfileLinks\u0026#34; $list = Get-UserProfileLinks #convert to xml $xmlBackup = $list | ConvertTo-FullXML -ObjectName \u0026#34;Link\u0026#34; -RootNodeName \u0026#34;Links\u0026#34; #write file $xmlBackup | Out-File -FilePath $filePath }\tCatch { throw $_.Exception.Message } Write-Host \u0026#34;Leave Export-UserProfileLinks\u0026#34; } Function Import-UserProfileLinks($configFilePath) { Try { Write-Host \u0026#34;Enter Import-UserProfileLinks\u0026#34; [xml] $configXml = Get-Content $configFilePath -Encoding UTF8 foreach ($link in $configXml.UserProfileLinks.UserProfileLink) { Edit-UserProfileLink $link } }\tCatch { throw $_.Exception.Message } Write-Host \u0026#34;Leave Import-UserProfileLinks\u0026#34; } Function Get-UserProfileLinks() { $profileManager = Get-UserProfileManager $profiles = $profileManager.GetEnumerator() $all = $profileManager.Count $collection = @() $num = 0 foreach ($profile in $profiles) { $userProfile = $profileManager.GetUserProfile($profile.AccountName); foreach ($link in $userProfile.QuickLinks.GetItems() ) { $myLink = [PSCustomObject]@{ AccountName = $profile.AccountName Title = $link.Title Url = $link.Url Group  = $link.Group  PrivacyLevel = $link.PrivacyLevel ID = $link.ID } $collection += $myLink } $num ++ if (0 -eq ($num % 1000)) { Write-Host \u0026#34;User profiles collected $num / $all\u0026#34; -ForegroundColor Gray } } Write-Host \u0026#34;User profiles $num collected\u0026#34; return $collection } function Edit-UserProfileLink($link) { Try { $profileManager = Get-UserProfileManager $userProfile = $profileManager.GetUserProfile($link.AccountName); $userProfile.QuickLinks.Create($link.Title, $link.Url, \u0026#34;UserSpecified\u0026#34;, $link.Group, $link.PrivacyLevel) | Out-Null }\tCatch { Write-Host \u0026#34;$($link.AccountName)cannot import $($link.Title)\u0026#34; -ForegroundColor DarkYellow } } function Get-UserProfileManager() { $caURL = (Get-SPWebApplication -IncludeCentralAdministration | Where-Object -FilterScript { $_.IsAdministrationWebApplication -eq $true }).Url $serviceContext = Get-SPServiceContext -Site $caURL return New-Object Microsoft.Office.Server.UserProfiles.UserProfileManager($serviceContext); } function ConvertTo-FullXML { [CmdletBinding()] param ( #Object to Input [Parameter(ValueFromPipeline)]$InputObject, #Name of the root document node. Defaults to \u0026#34;Objects\u0026#34; $RootNodeName = \u0026#34;Config\u0026#34;, $ObjectName = $null ) begin { [xml]$Doc = New-Object System.Xml.XmlDocument #Add XML Declaration $null = $doc.AppendChild($doc.CreateXmlDeclaration(\u0026#34;1.0\u0026#34;, \u0026#34;UTF-8\u0026#34;, $null)) #Add XML Root Node $root = $doc.AppendChild($doc.CreateElement($RootNodeName)) } process { if ($null -eq $ObjectName) { $elementname = $InputObject.gettype().name } else { $elementname = $ObjectName } $childObject = $doc.CreateElement($elementname) foreach ($propItem in $InputObject.psobject.properties) { $propNode = $doc.CreateElement($propItem.Name) $propNode.InnerText = $propItem.Value $null = $childObject.AppendChild($propNode) } $null = $root.AppendChild($childObject) } end { return $doc.outerxml } } To run with on export server\n$file = \u0026#34;c:\\temp\\profilelinks.xml\u0026#34; Export-UserProfileLinks $file And recreate it on import server\n$file = \u0026#34;c:\\temp\\profilelinks.xml\u0026#34; Import-UserProfileLinks $file Addition I like to mention there are also some solution to display these links in modern ui sample or sample 2\n","tags":["Migrate","PowerShell","SP2019","OnPremise"],"section":"post"},{"date":"1619913600","url":"https://conception365.com/post/2021-05-02-powerapps-sevdesk-technic/","title":"PowerApps TimeTracking for SevDesk Part 2","summary":"This article continues with technical details about my first part PowerApps TimeTracking for SevDesk. You have full access to the source code inside Office 365 PowerApps.\nCustom connector In general in PowerApps you need a data source for every app. This can be done by custom entities or with connectors. O365 brings you a lot of default connectors, if you have a third party system like SevDesk, you can create your own connector.","content":"This article continues with technical details about my first part PowerApps TimeTracking for SevDesk. You have full access to the source code inside Office 365 PowerApps.\nCustom connector In general in PowerApps you need a data source for every app. This can be done by custom entities or with connectors. O365 brings you a lot of default connectors, if you have a third party system like SevDesk, you can create your own connector. Connectors can be created in our solution folder (this solution helps just to package our app and the connector) or directly within Data \u0026gt; Custom Connectors.\nYou start with title, a description and your host url. To make it easier you can add the api/v1 to your basic url. It is attached to our host url.\n  On next step you choose your security option. SevDesk supports API-Key. You can get an overview here: hilfe.sevdesk.de/knowledge/sevdesk-rest-full-api\nWe choose the option API-Key and token for query. By running your connector, you are asked for your key. It is stored in a save connection and the connector will append this as hidden parameter to every request.\n  Your definition hold your request actions. I created the actions from official swagger documentation (app.swaggerhub.com/apis/sevDesk) first with postman. Afterwards i imported the statements from postman into the connector.\nYou should work with parameters and also add a sample response. PowerApps automatically adds these parameters to your preview and you can work with later.\n  A new smart option is to use the Swagger-Editor, you can enable this on top. Every parameter and response is visible here. Here a small sample:\n/ContactTimeTracking/Query/getAggregatedContactData: get: responses: default: description: default schema: type: object properties: fromApiCache: {type: boolean, description: fromApiCache} objects: type: object properties: objects: type: array items: type: object properties: contact: type: object properties: objectName: {type: string, description: objectName} id: {type: string, description: id} name: {type: string, description: name} description: contact date: {type: string, description: date} duration: {type: string, description: duration} quantity: {type: string, description: quantity} trackings: {type: integer, format: int32, description: trackings} used_trackings: {type: integer, format: int32, description: used_trackings} sumGross: {type: string, description: sumGross} sumTax: {type: string, description: sumTax} sumNet: {type: string, description: sumNet} description: objects total: {type: integer, format: int32, description: total} emptyState: {type: boolean, description: emptyState} description: objects summary: TimeTrackingAggregatedContactData parameters: - {name: embed, in: query, required: false, type: string, default: \u0026#39;contact,contact.parent,part\u0026#39;} - {name: limit, in: query, required: false, type: integer, default: 50} - {name: offset, in: query, required: false, type: integer, default: 0} operationId: TimeTrackingAggregatedContactData description: TimeTrackingAggregatedContactData The last step is to create your connector, create a connection and test your operation.\n  Post requests application/x-www-form-urlencoded Unfortunately SevDesk does not support post JSON requests for every type of request. We have to make a workaround. You have to create default request with a single body parameter. The body string we will build in our app and we do a post request with this content.\n/ContactTimeTracking/Factory/saveTrackedEvents: post: summary: Create a time tracking description: Create a time tracking operationId: CreateATimeTracking consumes: [application/x-www-form-urlencoded] produces: [application/json] parameters: - name: body in: body required: false schema: {type: string, title: bodycontent} responses: Further more you need to add a special policy. It makes sure, that your request header is Content-Type:application/x-www-form-urlencoded\n  SevDesk swagger definitions Here you can find two swagger definitions for SevDesk:\n SevDesk-TimeTracking-Connector.swagger.json TimeTracking.postman_collection.json-Swagger20.json taken from SevDesk Forum  Canvas App The canvas app is straight forward PowerApps default stuff. We define the data loading (in our case) on the OnVisible of the login/start screen. We just have to add our connector at the data pane and can access it from code. For example SevDesk.Contacts({}).objects, it queries the connector and write the result (with ClearCollect) into a separate collection.\n  You can have a look at your collections (after data are loaded)\n  You will also see on the ScreenForm \u0026gt; btnSave, our application/x-www-form-urlencoded encoded request. It is a little bit ugly but simple creates a content string with all needed parameters.\nSet(HttpMessage;Concatenate(\u0026#34;trackings%5B0%5D%5Bcreate%5D=\u0026#34;;If(isnew;\u0026#34;true\u0026#34;;\u0026#34;null\u0026#34;);\u0026#34;\u0026amp;trackings%5B0%5D%5Bupdate%5D=\u0026#34;;If(isnew;\u0026#34;null\u0026#34;;\u0026#34;true\u0026#34;);\u0026#34;\u0026amp;trackings%5B0%5D%5BsevClient%5D=null\u0026amp;trackings%5B0%5D%5Bcontact%5D%5Bid%5D=\u0026#34;;cbContacts.Selected.id;\u0026#34;\u0026amp;trackings%5B0%5D%5Bcontact%5D%5BobjectName%5D=Contact\u0026#34;;If(IsBlank(cbProjects.Selected.id);\u0026#34;\u0026amp;trackings%5B0%5D%5Bproject%5D=null\u0026#34;;Concatenate(\u0026#34;\u0026amp;trackings%5B0%5D%5Bproject%5D%5Bid%5D=\u0026#34;;cbProjects.Selected.id;\u0026#34;\u0026amp;trackings%5B0%5D%5Bproject%5D%5BobjectName%5D=Project\u0026#34;));\u0026#34;\u0026amp;trackings%5B0%5D%5Bpart%5D%5Bid%5D=\u0026#34;;cbParts.Selected.id;\u0026#34;\u0026amp;trackings%5B0%5D%5Bpart%5D%5BobjectName%5D=Part\u0026amp;trackings%5B0%5D%5Bemployee%5D%5Bid%5D=\u0026#34;;cbEmployee.Selected.id;\u0026#34;\u0026amp;trackings%5B0%5D%5Bemployee%5D%5BobjectName%5D=SevUser\u0026amp;trackings%5B0%5D%5Btracking%5D=null\u0026amp;trackings%5B0%5D%5BinvoicePos%5D=null\u0026amp;trackings%5B0%5D%5Bdate%5D=\u0026#34;;Text(DateDiff(Date(1970;1;1);dtDate.SelectedDate;Milliseconds)/1000);\u0026#34;\u0026amp;trackings%5B0%5D%5Bstatus%5D=null\u0026amp;trackings%5B0%5D%5Bbillable%5D=\u0026#34;;Text(cbBillable.Value);\u0026#34;\u0026amp;trackings%5B0%5D%5Bprecision%5D=PT1M\u0026amp;trackings%5B0%5D%5Bquantity%5D=null\u0026amp;trackings%5B0%5D%5BtaxRate%5D=19\u0026amp;trackings%5B0%5D%5BhourlyGross%5D=\u0026#34;;Substitute(Text(Value(txtNetHourPrice.Text )*Value(txtTax.Text)/100+Value(txtNetHourPrice.Text));\u0026#34;,\u0026#34;;\u0026#34;.\u0026#34;);\u0026#34;\u0026amp;trackings%5B0%5D%5BhourlyTax%5D=\u0026#34;;Substitute(Text(Value(txtNetHourPrice.Text )*Value(txtTax.Text)/100);\u0026#34;,\u0026#34;;\u0026#34;.\u0026#34;);\u0026#34;\u0026amp;trackings%5B0%5D%5BhourlyNet%5D=\u0026#34;;Text(Value(txtNetHourPrice.Text;\u0026#34;de-DE\u0026#34;);\u0026#34;[$-de-DE]###.##\u0026#34;);\u0026#34;\u0026amp;trackings%5B0%5D%5BsumGross%5D=null\u0026amp;trackings%5B0%5D%5BsumTax%5D=null\u0026amp;trackings%5B0%5D%5BsumNet%5D=null\u0026amp;trackings%5B0%5D%5BusedAt%5D=null\u0026amp;trackings%5B0%5D%5Bdescription%5D=\u0026#34;;txtDescription.Text;\u0026#34;\u0026amp;trackings%5B0%5D%5BobjectName%5D=ContactTimeTracking\u0026amp;trackings%5B0%5D%5Btypes%5D=%5Bobject+Object%5D\u0026amp;trackings%5B0%5D%5Bid%5D=\u0026#34;;If(isnew;\u0026#34;null\u0026#34;;id);\u0026#34;\u0026amp;trackings%5B0%5D%5BmapAll%5D=true\u0026amp;trackings%5B0%5D%5Bduration%5D=null\u0026amp;durations=%5B%7B%22unit%22%3A%22date_interval%22%2C%22value%22%3A%22\u0026#34;;Substitute(txtQuantityHour.Text;\u0026#34;:\u0026#34;;\u0026#34;%3A\u0026#34;);\u0026#34;%22%7D%5D\u0026#34;;If(IsBlank(cbProjects.Selected.id);\u0026#34;\u0026#34;;\u0026#34;\u0026amp;projects=null\u0026#34;);If(IsBlank(cbProjects.Selected.id);Concatenate(\u0026#34;\u0026amp;projects%5B0%5D%5Bcreate%5D=null\u0026amp;projects%5B0%5D%5Bupdate%5D=null\u0026amp;projects%5B0%5D%5BsevClient%5D=null\u0026amp;projects%5B0%5D%5Bcontact%5D=null\u0026amp;projects%5B0%5D%5Bname%5D=\u0026#34;;cbProjects.SearchText;\u0026#34;\u0026amp;projects%5B0%5D%5BobjectName%5D=Project\u0026amp;projects%5B0%5D%5Btypes%5D=%5Bobject Object%5D\u0026amp;projects%5B0%5D%5Bid%5D=null\u0026amp;projects%5B0%5D%5BmapAll%5D=true\u0026#34;);\u0026#34;\u0026#34;);\u0026#34;\u0026amp;parts%5B0%5D%5BobjectName%5D=Part\u0026amp;parts%5B0%5D%5BmapAll%5D=true\u0026#34;));;SevDesk.CreateATimeTracking({body:HttpMessage});;Navigate(ScreenSuccess;ScreenTransition.Cover);;If(IsBlank(cbProjects.Selected.id);ClearCollect(Projects;SevDesk.Projects({}).objects));; Filter and expand collections I also had the problem, if you like to search your entries, it is done in your list control. You define a collection and make a search request on a special column. In this case it is called \u0026ldquo;name\u0026rdquo;.\nSortByColumns(If(IsBlank( txtSearchContact.Text);ContactQuery;Search(ContactQuery; txtSearchContact.Text;\u0026#34;name\u0026#34;)); \u0026#34;date\u0026#34;; If(SortDescending1; SortOrder.Ascending; SortOrder.Descending)) The \u0026ldquo;name\u0026rdquo; column was not directly in our collection available. I had a more complex response structure:\n[ {contact:{name:\u0026#34;Contact 1\u0026#34;}, date:\u0026#34;2021-01-01\u0026#34;, duration:\u0026#34;01:00\u0026#34;,...} {contact:{name:\u0026#34;Contact 2\u0026#34;}, date:\u0026#34;2021-01-02\u0026#34;, duration:\u0026#34;02:00\u0026#34;,...} ] So you can do a small workaround and expand the result into another flat collection.\nClearCollect(ContactQueryData;SevDesk.TimeTrackingAggregatedContactData({}).objects.objects);;ClearCollect(ContactQuery;AddColumns(ContactQueryData;\u0026#34;name\u0026#34;;contact.name));;Clear(ContactQueryData);; The searchable result looks like:\n[ {name:\u0026#34;Contact 1\u0026#34;, date:\u0026#34;2021-01-01\u0026#34;, duration:\u0026#34;01:00\u0026#34;,...} {name:\u0026#34;Contact 2\u0026#34;, date:\u0026#34;2021-01-02\u0026#34;, duration:\u0026#34;02:00\u0026#34;,...} ] I hope this will get you some insides for building the application.\n","tags":["PowerApps","SevDesk"],"section":"post"},{"date":"1619740800","url":"https://conception365.com/post/2021-04-30-powerapps-sevdesk-guide/","title":"PowerApps TimeTracking for SevDesk","summary":"I was looking for a smart and simple mobile time tracking solution connected to SevDesk. SevDesk has no mobile solution for time tracking module. Existing third party apps where not fully fit my requirements. I was satisfied with the default module and implemented a mobile app with Office 365 - PowerApps.\n  Source: sevdesk.de\nThis was done a while a go, but I decided now to publish the sources to help you build your own.","content":"I was looking for a smart and simple mobile time tracking solution connected to SevDesk. SevDesk has no mobile solution for time tracking module. Existing third party apps where not fully fit my requirements. I was satisfied with the default module and implemented a mobile app with Office 365 - PowerApps.\n  Source: sevdesk.de\nThis was done a while a go, but I decided now to publish the sources to help you build your own. Currently i use a different project specific time tracking solution, but the app did his job very well. I created a smart overview for you to see the app in action.\n  Features You will find following features in the app\n Customer related time overview Add hours to your customer Create, edit and delete project related time entries Choose task/service from inventory Small search and filters  Not implemented is:\n Track time for specific times, only durations are possible Track multiple durations per entry, only per project  Solution + Installation The solution is a complete PowerApp Solution Package contains the canvas app and a custom connector. PowerApps is completely open and transparent. After installation you can view the complete \u0026ldquo;source code\u0026rdquo; by editing the app or the connector inside the solution.\nDownload the solution Solution\nGo to your environment make.powerapps.com and open project solutions from left navigation. On first opening you are asked for creating a new database. (This is only with correct license possible) Go to \u0026ldquo;new Solution\u0026rdquo; and upload the app. This takes some time, a small message \u0026ldquo;SevDesk -Timetracking is currently imported\u0026hellip;\u0026rdquo; is displayed during upload process. Now you will see the solution and afterwards you will the the app in your list.\n  On your first run you will be asked by the PowerApps connector for your permission to connect.\n  Afterwards you have to enter your API-Key. The key is not visible to someone and is user related / specific.\n  You can find the key on your SevDesk user page. Don\u0026rsquo;t share this key everywhere else!\n  For using this app, you should have a valid product entry.\n  Have fun, you can use the app from your mobile phone!\nI will publish some details about the general technical implementation on a separate article.\nDisclaimer Please notice this is just a sample project with some requirements:\n I could not give any support I don\u0026rsquo;t give any warranty You need a SevDesk time tracking license You need a Office 365 PowerApps license You need some basic knowledge about O365 PowerApps  Continue reading technical details on PowerApps TimeTracking for SevDesk Part 2.\n","tags":["PowerApps","SevDesk"],"section":"post"},{"date":"1619049600","url":"https://conception365.com/post/2021-04-22-spfx-2019-prettier-eslint/","title":"SPFX 2019 eslint and prettier","summary":"For our current projects we used tslint and suffered for some problems. First main concern was, that VSCode was not able to give full feedback about code problems. Later on execution of gulp build all errors where thrown. Furthermore we got some conflicts with prettier solution and it was a hell to understand the current used rules from tslint. Also the tslint performance was very awful. We know it is deprecated for a while source and now its time to get rid of it.","content":"For our current projects we used tslint and suffered for some problems. First main concern was, that VSCode was not able to give full feedback about code problems. Later on execution of gulp build all errors where thrown. Furthermore we got some conflicts with prettier solution and it was a hell to understand the current used rules from tslint. Also the tslint performance was very awful. We know it is deprecated for a while source and now its time to get rid of it.\nWe decided to move to current state of art eslint and there was a good starting point from Sergei Sergeev. source. From my point of view we cannot come alone with the eslint rule set, we need a good code formatter solution, too. Luckily there is a good solution with prettier, it works with a combined rule set. Here i will introduce a full demo solution for SPFX 2019 with react.\nYou can find the source code here.\nESLint and prettier motivation I found a really god explanation from Joel Reis, why it makes sense to use these tools together\n When building apps, it\u0026rsquo;s important to have a good setup of automated and manual tools that ensures the best standards and code quality. Each project must have a linting tool to fulfill these needs. Both tools are configurable and they work well together, each one having a different linting responsibility between programming and stylistic errors, making it easy to catch errors.\nESLint is one of the most used linting tools and there is a reason for it. Highly configurable, it has a huge adoption from the community having hundreds of open-source configurations and plugins. It allows the configuration of several options like coding rules, environments, parser options, extend configurations, and use plugins.\nOn one hand, ESLint is responsible for checking against programming errors, on the other hand, we have Prettier an opinionated code formatter capable of finding any stylistic errors. It comes with some code style standards and is also easy to configure. It\u0026rsquo;s easy to integrate with ESLint and has Code Editor extensions that can format the code on save!\n \u0026ldquo;Joel Reis\u0026rdquo; source\nPrerequisite For SPFX 2019 we have normally to use Node version 8, this is not more possible with eslint and we have to upgrade to Node version 10. The good news is, we had very good experiences to using this newer version and no major issues about that. So just check your node version.\nnode -v v10.22.0 Packages We need packages for eslint and prettier in our package.json under devDependencies section, we also need a fresh typescript version:\nPackage.json\n\u0026#34;@typescript-eslint/eslint-plugin\u0026#34;: \u0026#34;^4.22.0\u0026#34;, \u0026#34;@typescript-eslint/parser\u0026#34;: \u0026#34;^4.22.0\u0026#34;, \u0026#34;eslint\u0026#34;: \u0026#34;^7.24.0\u0026#34;, \u0026#34;eslint-config-prettier\u0026#34;: \u0026#34;^8.2.0\u0026#34;, \u0026#34;eslint-plugin-prettier\u0026#34;: \u0026#34;^3.4.0\u0026#34;, \u0026#34;eslint-plugin-react\u0026#34;: \u0026#34;^7.23.2\u0026#34;, \u0026#34;gulp\u0026#34;: \u0026#34;~3.9.1\u0026#34;, \u0026#34;gulp-eslint\u0026#34;: \u0026#34;^6.0.0\u0026#34;, \u0026#34;prettier\u0026#34;: \u0026#34;2.2.1\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;3.6.5\u0026#34; Or with command line\nnpm i --save-dev @typescript-eslint/eslint-plugin @typescript-eslint/parser eslint eslint-config-prettier eslint-plugin-prettier eslint-plugin-react gulp gulp-eslint prettier typescript@3.6.5 ESLint config Our main configuration goes to .eslintrc.json. We register on extensions 4 rule sets, you will find several specific details about your rules:\n{ \u0026#34;root\u0026#34;: true, \u0026#34;env\u0026#34;: { \u0026#34;browser\u0026#34;: true, \u0026#34;node\u0026#34;: true }, \u0026#34;extends\u0026#34;: [ \u0026#34;eslint:recommended\u0026#34;, \u0026#34;plugin:react/recommended\u0026#34;, \u0026#34;plugin:@typescript-eslint/recommended\u0026#34;, \u0026#34;prettier\u0026#34; ], \u0026#34;parser\u0026#34;: \u0026#34;@typescript-eslint/parser\u0026#34;, \u0026#34;parserOptions\u0026#34;: { \u0026#34;ecmaFeatures\u0026#34;: { \u0026#34;jsx\u0026#34;: true }, \u0026#34;ecmaVersion\u0026#34;: 12, \u0026#34;sourceType\u0026#34;: \u0026#34;module\u0026#34; }, \u0026#34;plugins\u0026#34;: [\u0026#34;react\u0026#34;, \u0026#34;@typescript-eslint\u0026#34;, \u0026#34;prettier\u0026#34;], \u0026#34;rules\u0026#34;: { \u0026#34;prettier/prettier\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;no-use-before-define\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;@typescript-eslint/no-use-before-define\u0026#34;: [\u0026#34;error\u0026#34;], \u0026#34;no-multiple-empty-lines\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;no-multi-spaces\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;no-var\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;@typescript-eslint/ban-ts-comment\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;semi\u0026#34;: [\u0026#34;error\u0026#34;, \u0026#34;always\u0026#34;] }, \u0026#34;ignorePatterns\u0026#34;: [ \u0026#34;*.js\u0026#34;, \u0026#34;**/coverage\u0026#34;, \u0026#34;**/dist\u0026#34;, \u0026#34;**/etc\u0026#34;, \u0026#34;**/lib\u0026#34;, \u0026#34;**/sharepoint\u0026#34;, \u0026#34;**/lib-amd\u0026#34;, \u0026#34;**/lib-commonjs\u0026#34;, \u0026#34;**/node_modules\u0026#34;, \u0026#34;**/temp\u0026#34;, \u0026#34;**/*.scss.ts\u0026#34; ], \u0026#34;settings\u0026#34;: { \u0026#34;react\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;detect\u0026#34; } } } extends  eslint:recommended basic eslint rules plugin:react/recommended react based rules plugin:@typescript-eslint/recommended our typescript specific rules prettier rules to hold format and eslint rules together  plugins Just register our functions\nrules Here you can override rules by your own project specific settings. For bigger projects it maybe makes sense to create an own rule set.\nignorePatterns We like to exclude everything what is not our source code.\nsettings We need for react a specific setting, to detect our react version.\nIntegration Now we like to replace our default tslint build process with custom eslint task in gulpfile.js. We create a new prebuild Task for eslint and disable tslint. Futhermore we need to register the current typescript version.\n\u0026#34;use strict\u0026#34;; const build = require(\u0026#34;@microsoft/sp-build-web\u0026#34;); const eslint = require(\u0026#34;gulp-eslint\u0026#34;); const typeScriptConfig = require(\u0026#34;@microsoft/gulp-core-build-typescript/lib/TypeScriptConfiguration\u0026#34;); const buildtypescript = require(\u0026#34;@microsoft/gulp-core-build-typescript\u0026#34;); typeScriptConfig.TypeScriptConfiguration.setTypescriptCompiler( require(\u0026#34;typescript\u0026#34;) ); buildtypescript.tslint.enabled = false; const eslintSubTask = build.subTask( \u0026#34;eslint\u0026#34;, function (gulp, buildOptions, done) { return ( gulp .src([\u0026#34;src/**/*.{ts,tsx}\u0026#34;]) // eslint() attaches the lint output to the \u0026#34;eslint\u0026#34; property  // of the file object so it can be used by other modules.  .pipe(eslint()) // eslint.format() outputs the lint results to the console.  // Alternatively use eslint.formatEach() (see Docs).  .pipe(eslint.format()) // To have the process exit with an error code (1) on  // lint error, return the stream and pipe to failAfterError last.  .pipe(eslint.failAfterError()) ); } ); build.addSuppression( `Warning - [sass] The local CSS class \u0026#39;ms-Grid\u0026#39; is not camelCase and will not be type-safe.` ); build.rig.addPreBuildTask(build.task(\u0026#34;eslint-task\u0026#34;, eslintSubTask)); build.initialize(require(\u0026#34;gulp\u0026#34;)); Prettier We need a basic configuration file .prettierrc.yaml to set our prettier. You can find here the most important options.\n{ \u0026#34;singleQuote\u0026#34;: true, # use quotes instead of double quotes \u0026#34;jsxSingleQuote\u0026#34;: true, # single quotes for jsx \u0026#34;jsxBracketSameLine\u0026#34;: true, # closing bracked in same line \u0026#34;arrowParens\u0026#34;: \u0026#34;always\u0026#34;, # use bracked in arrow functions \u0026#34;printWidth\u0026#34;: 120, # preferred width (not same as eslint max-length) \u0026#34;tabWidth\u0026#34;: 2, # number of spaces \u0026#34;useTabs\u0026#34;: false, # spaces instead of tabs \u0026#34;semi\u0026#34;: true, # semicolons at ends of statement \u0026#34;trailingComma\u0026#34;: \u0026#34;none\u0026#34;, # removes trailing comma inside objects \u0026#34;htmlWhitespaceSensitivity\u0026#34;: \u0026#34;strict\u0026#34;, # whitespace inside html is significant \u0026#34;endOfLine\u0026#34;: \u0026#34;auto\u0026#34;, # correct end of line } And we need to ignore some files .prettierignore:\n# Ignore artifacts: sharepoint lib node_modules temp dist Plugins for VSCode VSCode extensions are helping us a lot to make the integration with eslint and prettier. You will find these two extensions here:\n dbaeumer.vscode-eslint esbenp.prettier-vscode  To work i recommend to update your settings.json inside .vscode folder:\n\u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, #enable prettier as default formatter \u0026#34;prettier.configPath\u0026#34;: \u0026#34;./.prettierrc.yaml\u0026#34;, #set config file \u0026#34;editor.formatOnSave\u0026#34;: true #set format on save Run Now you also can format your complete project by running just one line\nPS C:\\daten\\git\\spfx-2019-prettier\u0026gt; npm run format \u0026gt; spfx-2019-prettier@0.0.1 format C:\\daten\\git\\spfx-2019-prettier \u0026gt; npx prettier --write . --config .prettierrc.yaml .eslintrc.json 105ms .prettierrc.yaml 85ms .vscode\\extensions.json 9ms .vscode\\launch.json 47ms .vscode\\settings.json 13ms .yo-rc.json 21ms config\\config.json 27ms config\\copy-assets.json 12ms config\\deploy-azure-storage.json 15ms Furthermore you can also use the eslint fix option.\nPS C:\\daten\\git\\spfx-2019-prettier\u0026gt; npm run fix \u0026gt; spfx-2019-prettier@0.0.1 fix C:\\daten\\git\\spfx-2019-prettier \u0026gt; npx eslint src/ --fix --ext .ts --ext .tsx C:\\daten\\git\\spfx-2019-prettier\\src\\webparts\\helloWorld\\components\\HelloWorld.tsx 6:75 error Don\u0026#39;t use `{}` as a type. `{}` actually means \u0026#34;any non-nullish value\u0026#34;. - If you want a type meaning \u0026#34;any object\u0026#34;, you probably want `Record\u0026lt;string, unknown\u0026gt;` instead. - If you want a type meaning \u0026#34;any value\u0026#34;, you probably want `unknown` instead. - If you want a type meaning \u0026#34;empty object\u0026#34;, you probably want `Record\u0026lt;string, never\u0026gt;` instead @typescript-eslint/ban-types ✖ 1 problem (1 error, 0 warnings) npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! spfx-2019-prettier@0.0.1 fix: `npx eslint src/ --fix --ext .ts --ext .tsx` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the spfx-2019-prettier@0.0.1 fix script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: You should fix your errors:\nexport default class HelloWorld extends React.Component\u0026lt;IHelloWorldProps, unknown\u0026gt; { And you will run a pretty fast build with everything together:\nPS C:\\daten\\git\\spfx-2019-prettier\u0026gt; npm run package \u0026gt; spfx-2019-prettier@0.0.1 package C:\\daten\\git\\spfx-2019-prettier \u0026gt; gulp clean \u0026amp;\u0026amp; gulp bundle \u0026amp;\u0026amp; gulp package-solution Build target: DEBUG [20:56:49] Using gulpfile C:\\daten\\git\\spfx-2019-prettier\\gulpfile.js [20:56:49] Starting gulp [20:56:49] Starting \u0026#39;clean\u0026#39;... [20:56:49] Starting subtask \u0026#39;clean\u0026#39;... [20:56:49] Finished subtask \u0026#39;clean\u0026#39; after 25 ms [20:56:49] Finished \u0026#39;clean\u0026#39; after 32 ms [20:56:50] ==================[ Finished ]================== [20:56:50] Project spfx-2019-prettier version: 0.0.1 [20:56:50] Build tools version: 3.2.7 [20:56:50] Node version: v10.22.0 [20:56:50] Total duration: 6.41 s Build target: DEBUG [20:56:58] Using gulpfile C:\\daten\\git\\spfx-2019-prettier\\gulpfile.js [20:56:58] Starting gulp [20:56:58] Starting \u0026#39;bundle\u0026#39;... [20:56:58] Starting subtask \u0026#39;configure-sp-build-rig\u0026#39;... [20:56:58] Finished subtask \u0026#39;configure-sp-build-rig\u0026#39; after 25 ms [20:56:58] Starting subtask \u0026#39;pre-copy\u0026#39;... [20:56:58] Finished subtask \u0026#39;pre-copy\u0026#39; after 42 ms [20:56:58] Starting subtask \u0026#39;eslint\u0026#39;... [20:57:04] Finished subtask \u0026#39;eslint\u0026#39; after 5.61 s From now on you have a good boilerplate to use eslint and prettier together on your spfx 2019 projects.\n","tags":["SP2019","SPFX","eslint","prettier"],"section":"post"},{"date":"1616198400","url":"https://conception365.com/post/2021-03-20-spfx-2019-libraries/","title":"SPFX 2019 Libraries with PnP JS","summary":"What we create Ok. Here a small preview, what we like to create in this guide. A sample webpart loading your code from a library, here together with PnP JS to get all site groups.\n  You find the complete source code for the solution here.\nWhat are SPFX libraries? If we come to the library topic most people start with the default description from microsoft. (source)\n The library component type in the SharePoint Framework (SPFx) enables you to have independently versioned and deployed code served automatically for the SharePoint Framework components with a deployment through an app catalog.","content":"What we create Ok. Here a small preview, what we like to create in this guide. A sample webpart loading your code from a library, here together with PnP JS to get all site groups.\n  You find the complete source code for the solution here.\nWhat are SPFX libraries? If we come to the library topic most people start with the default description from microsoft. (source)\n The library component type in the SharePoint Framework (SPFx) enables you to have independently versioned and deployed code served automatically for the SharePoint Framework components with a deployment through an app catalog. Library components provide you an alternative option to create shared code, which can be then used and referenced cross all the components in the tenant.\n Yes i agree all these advantages - I like to start with SharePoint 2019 and use these. What we don\u0026rsquo;t really learn is, nope - you won\u0026rsquo;t get this! Ok after some deep dive i learned a lot and share you some about that. - And of course created a solution.\nLibrary is not library In SharePoint SPFX context the wording library is used a lot, but there are different use cases.\nCode share First is, we like to put our code into another solution and reuse it between multiple projects. On a code perspective this is relative easy, you can basically create a npm package and share this code by default packaging mechanism with npm. You can find a short description about that here. But now is our code included inside our main project, so yes it is reused but not shared. We like to build real libraries and also exclude code from our main SPFX files. So we have to continue.\nExternals To exclude code, we can use externals on our SPFX project. We can find some details from Microsoft here\n Your client-side solution might include multiple web parts. These web parts might need to import or share the same library. In such cases, instead of bundling the library, you should include it in a separate JavaScript file to improve performance and caching. This is especially true of larger libraries.\n This will help us to get our code outside. You will see two methods AMD and non-AMD modules. You find a good description about that on the same article, but it does not help you so much for our specific problem. How we tell sharepoint to build our library code as external?\nLibrary component The Library component brings a technical solution. You define a special manifest json with a library component type. Also you define in your config a special bundle with this type.\nconfig.json\n\u0026#34;bundles\u0026#34;: { \u0026#34;repository-library\u0026#34;: { \u0026#34;components\u0026#34;: [ { \u0026#34;entrypoint\u0026#34;: \u0026#34;./lib/libraries/repository/RepositoryLibrary.js\u0026#34;, \u0026#34;manifest\u0026#34;: \u0026#34;./src/libraries/repository/RepositoryLibrary.manifest.json\u0026#34; } ] } RepositoryLibrary.manifest.json\n{ \u0026#34;id\u0026#34;: \u0026#34;27ce84c6-8b9a-470f-9468-adb991bbb2e9\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;RepositoryLibrary\u0026#34;, \u0026#34;componentType\u0026#34;: \u0026#34;Library\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;manifestVersion\u0026#34;: 2 } Taken from sp-dev-fx-library-components.\nNow the concept is, to deploy your component within a SPFX solution and load this inside your actual webpart.\nIf we like to use this library component inside SharePoint 2019 OnPremise we will see, yes it builds a solution and yes you could create a correct SPFX solution. But, it will not work and nothing happens correct. So i started to look for the reason and the short answer is, it is just supported from SPFX version 1.8.1 and not available for version 1.4.1.\nYou can build your solution, because your webpack compiler understands the type of bundle. Inside webpack is also a configuration called library, what creates a correct bundle. After deploy the solution to SharePoint 2019 AppCatalog it will fail. SharePoint cannot interpret this type correct and there is also missing inside SharePoint 2019 the background technology to load these libraries inside a site page. Technical SharePoint creates a list for all libraries inside the app catalog and loads these libraries if requested. Like it is working with other default Microsoft components.\nCustom libraries So after this fail with library components, i went back to focus on the external topic and decided to create a separate package loaded by the default externals mechanism. This is working also in older versions of SPFX. The challenge is to allow bundling and get a sweet typescript support.\nHow to create a custom library? We start with separate npm project for our library.\npackage.json\n{ \u0026#34;name\u0026#34;: \u0026#34;@custom/spfx-2019-lib\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;lib/index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;, \u0026#34;package\u0026#34;: \u0026#34;gulp clean \u0026amp;\u0026amp; tsc -p tsconfig.json \u0026amp;\u0026amp; webpack --config webpack.config.js\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;@microsoft/sp-application-base\u0026#34;: \u0026#34;1.4.1\u0026#34;, \u0026#34;@microsoft/sp-core-library\u0026#34;: \u0026#34;1.4.1\u0026#34;, \u0026#34;@microsoft/sp-webpart-base\u0026#34;: \u0026#34;1.4.1\u0026#34;, \u0026#34;@pnp/sp\u0026#34;: \u0026#34;2.0.13\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/es6-promise\u0026#34;: \u0026#34;0.0.33\u0026#34;, \u0026#34;@types/microsoft-ajax\u0026#34;: \u0026#34;0.0.33\u0026#34;, \u0026#34;@types/sharepoint\u0026#34;: \u0026#34;2016.1.2\u0026#34;, \u0026#34;@types/webpack-env\u0026#34;: \u0026#34;1.14.1\u0026#34;, \u0026#34;del\u0026#34;: \u0026#34;5.1.0\u0026#34;, \u0026#34;gulp\u0026#34;: \u0026#34;^3.9.1\u0026#34;, \u0026#34;webpack\u0026#34;: \u0026#34;4.42.0\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^3.3.11\u0026#34;, \u0026#34;fork-ts-checker-webpack-plugin\u0026#34;: \u0026#34;4.1.0\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;3.6.4\u0026#34; } } We define a name @custom/spfx-2019-lib and add our dependencies. Furthermore we create a custom webpack to create a smart bundle.\nwebpack.config.json (not full version)\nconst path = require(\u0026#39;path\u0026#39;); const del = require(\u0026#39;del\u0026#39;); const ForkTsCheckerWebpackPlugin = require(\u0026#39;fork-ts-checker-webpack-plugin\u0026#39;); const webpack = require(\u0026#39;webpack\u0026#39;); var PACKAGE = require(\u0026#39;./package.json\u0026#39;); var version = PACKAGE.version.replace(/\\./g, \u0026#39;_\u0026#39;); ... module.exports = [\u0026#39;source-map\u0026#39;].map((devtool) =\u0026gt; ({ mode: \u0026#39;development\u0026#39;, entry: { \u0026#34;spfx2019lib\u0026#34;: \u0026#39;./lib/index.js\u0026#39; }, resolve: { extensions: [\u0026#39;.ts\u0026#39;, \u0026#39;.tsx\u0026#39;, \u0026#39;.js\u0026#39;], modules: [\u0026#39;node_modules\u0026#39;] }, context: path.resolve(__dirname), output: { path: path.resolve(__dirname, \u0026#39;dist\u0026#39;), chunkFilename: \u0026#39;[id].[name]_[chunkhash].js\u0026#39;, filename: \u0026#39;[name].js\u0026#39;, library: \u0026#39;[name]_\u0026#39; + version, libraryTarget: \u0026#39;var\u0026#39;, umdNamedDefine: true, devtoolModuleFilenameTemplate: \u0026#39;webpack:///../[resource-path]\u0026#39;, devtoolFallbackModuleFilenameTemplate: \u0026#39;webpack:///../[resource-path]?[hash]\u0026#39; }, devtool, optimization: { runtimeChunk: false }, performance: { hints: false }, externals: [ \u0026#39;@microsoft/decorators\u0026#39;, \u0026#39;@microsoft/sp-lodash-subset\u0026#39;, \u0026#39;@microsoft/sp-core-library\u0026#39;, \u0026#39;@microsoft/office-ui-fabric-react-bundle\u0026#39;, \u0026#39;@microsoft/sp-polyfills\u0026#39;, \u0026#39;@microsoft/sp-loader\u0026#39;, \u0026#39;@microsoft/sp-http\u0026#39;, \u0026#39;@microsoft/sp-page-context\u0026#39;, \u0026#39;@microsoft/sp-component-base\u0026#39;, \u0026#39;@microsoft/sp-extension-base\u0026#39;, \u0026#39;@microsoft/sp-application-base\u0026#39;, \u0026#39;@microsoft/sp-webpart-base\u0026#39;, \u0026#39;@microsoft/sp-dialog\u0026#39;, \u0026#39;@microsoft/sp-office-ui-fabric-core\u0026#39;, \u0026#39;@microsoft/sp-client-preview\u0026#39;, \u0026#39;@microsoft/sp-webpart-workbench\u0026#39; ], module: { ... }, plugins: [ new webpack.optimize.LimitChunkCountPlugin({ maxChunks: 1 }), new ForkTsCheckerWebpackPlugin({ tslint: false }), new ClearCssModuleDefinitionsPlugin(), new webpack.DefinePlugin({ \u0026#39;process.env.NODE_ENV\u0026#39;: JSON.stringify(process.env.NODE_ENV), \u0026#39;process.env.DEBUG\u0026#39;: JSON.stringify(true), DEBUG: JSON.stringify(true) }) ] })); The most important thing is the filename:\n\u0026#34;spfx2019lib\u0026#34;: \u0026#39;./lib/index.js\u0026#39; And our library target, it is an old UMD module. So we package everything into a variable.\nlibraryTarget: \u0026#39;var\u0026#39;, umdNamedDefine: true, I tried to use newer AMD module definition, but again SharePoint 2019 cannot handle this correct. It was a problem with loading the modules inside application extensions, here it was breaking. For old UMD modules, everything works correct.\nI implemented also a small service inside the solution, working with latest PnP version.\nPnPService.ts\nimport { sp } from \u0026#34;@pnp/sp\u0026#34;; import \u0026#34;@pnp/sp/webs\u0026#34;; import \u0026#34;@pnp/sp/site-groups\u0026#34;; import { ISiteGroupInfo } from \u0026#34;../interfaces/models/ISiteGroupInfo\u0026#34;; import { IPnPService } from \u0026#34;../interfaces/IPnPService\u0026#34;; export class PnPService implements IPnPService { constructor(absoluteWebUrl:string){ sp.setup({ sp: { baseUrl: absoluteWebUrl } }); } /** * Get all site groups */ public async getAllSiteGroups(): Promise\u0026lt;ISiteGroupInfo[]\u0026gt; { return await sp.web.siteGroups.get() as ISiteGroupInfo[]; } } One important thing is, to use own interfaces and also export everything on the index.ts. Your package also links to this file \u0026ldquo;main\u0026rdquo;: \u0026ldquo;lib/index.js\u0026rdquo;.\nindex.ts\nexport * from \u0026#39;./interfaces\u0026#39;; export * from \u0026#39;./services\u0026#39;; Now you will get a correct library\nnpm run package \u0026gt; @custom/spfx-2019-lib@1.0.0 package C:\\daten\\git\\spfx-2019-solution\\spfx-2019-lib \u0026gt; gulp clean \u0026amp;\u0026amp; tsc -p tsconfig.json \u0026amp;\u0026amp; webpack --config webpack.config.js [17:02:31] Using gulpfile C:\\daten\\git\\spfx-2019-solution\\spfx-2019-lib\\gulpfile.js [17:02:31] Starting \u0026#39;clean\u0026#39;... [17:02:31] Finished \u0026#39;clean\u0026#39; after 76 ms Starting type checking service... Hash: abe77e4dd0d7cd747042 Version: webpack 4.42.0 Child Hash: abe77e4dd0d7cd747042 Time: 2930ms Built at: 2021-05-07 5:02:42 PM Asset Size Chunks Chunk Names spfx2019lib.js 334 KiB spfx2019lib [emitted] [big] spfx2019lib spfx2019lib.js.map 286 KiB spfx2019lib [emitted] [dev] spfx2019lib Entrypoint spfx2019lib [big] = spfx2019lib.js spfx2019lib.js.map [./lib/index.js] 62 bytes {spfx2019lib} [built] [./lib/services/PnPService.js] 3.27 KiB {spfx2019lib} [built] [./lib/services/index.js] 64 bytes {spfx2019lib} [built] [./node_modules/webpack/buildin/global.js] (webpack)/buildin/global.js 472 bytes {spfx2019lib} [built] + 53 hidden modules Include this into your project General Now we reuse or library inside our other project, we create a symlink by just adding this to your package configuration.\npackage.json\n\u0026#34;dependencies\u0026#34;: { \u0026#34;@custom/spfx-2019-lib\u0026#34;: \u0026#34;file:../spfx-2019-lib\u0026#34;, ... }, Inside our config we declare to use this project as external. The global name is defined inside your library project. The bundle mechanism will exclude all code into a separate file.\n\u0026#34;externals\u0026#34;: { \u0026#34;@custom/spfx-2019-lib\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;./node_modules/@custom/spfx-2019-lib/dist/spfx2019lib.js\u0026#34;, \u0026#34;globalName\u0026#34;: \u0026#34;spfx2019lib_1_0_0\u0026#34; } Now we can use this library inside your webpart. It is important just use the package name \u0026quot;@custom/spfx-2019-lib\u0026quot; and NO subpath (lib/\u0026hellip;). Only code with exact package name will excluded into separate file.\nHelloWorld.tsx\nimport { ISiteGroupInfo, PnPService } from \u0026#34;@custom/spfx-2019-lib\u0026#34;; ... public async componentDidMount(): Promise\u0026lt;void\u0026gt; { const service = new PnPService(this.props.absoluteWebUrl); let groups = await service.getAllSiteGroups(); this.setState({ groups: groups }); } PnP Specific For our PnP stuff we have to tell our compiler to use latest typescript. This is done in our gulp file.\ngulpfile.js\nconst typeScriptConfig = require(\u0026#39;@microsoft/gulp-core-build-typescript/lib/TypeScriptConfiguration\u0026#39;); typeScriptConfig.TypeScriptConfiguration.setTypescriptCompiler(require(\u0026#39;typescript\u0026#39;)); const buildtypescript = require(\u0026#39;@microsoft/gulp-core-build-typescript\u0026#39;); buildtypescript.tslint.enabled = false; PnP js has also a problem with source map typings, we disable this in our build configuration.\nfunction includeRuleForSourceMapLoader(rules) { for (const rule of rules) { if (rule.use \u0026amp;\u0026amp; typeof rule.use === \u0026#39;string\u0026#39; \u0026amp;\u0026amp; rule.use.indexOf(\u0026#39;source-map-loader\u0026#39;) !== -1) { rule.include = [path.resolve(__dirname, \u0026#39;lib\u0026#39;), path.resolve(__dirname, \u0026#39;node_modules\u0026#39;, \u0026#39;spfx-2019-lib\u0026#39;)]; } } } build.configureWebpack.mergeConfig({ additionalConfiguration: (generatedConfiguration) =\u0026gt; { //we dont like to include all source maps  includeRuleForSourceMapLoader(generatedConfiguration.module.rules); return generatedConfiguration; } }); Run it You can run it and build your spfx solution.\nPS C:\\daten\\git\\spfx-2019-solution\\spfx-2019\u0026gt; npm run package-ship \u0026gt; spfx-2019@0.0.1 package-ship C:\\daten\\git\\spfx-2019-solution\\spfx-2019 \u0026gt; gulp clean \u0026amp;\u0026amp; gulp build \u0026amp;\u0026amp; gulp bundle --ship \u0026amp;\u0026amp; gulp package-solution --ship ... [17:22:57] Finished subtask \u0026#39;package-solution\u0026#39; after 1.09 s [17:22:57] Finished \u0026#39;package-solution\u0026#39; after 1.14 s [17:22:57] ==================[ Finished ]================== [17:22:58] Project spfx-2019 version: 0.0.1 [17:22:58] Build tools version: 3.2.7 [17:22:58] Node version: v10.22.0 [17:22:58] Total duration: 8.09 s You can see our library inside the manifests.json (located in the temp folder).\nmanifests.json\n\u0026#34;loaderConfig\u0026#34;: { \u0026#34;entryModuleId\u0026#34;: \u0026#34;hello-world-web-part\u0026#34;, \u0026#34;internalModuleBaseUrls\u0026#34;: [ \u0026#34;https://localhost:4321/\u0026#34; ], \u0026#34;scriptResources\u0026#34;: { \u0026#34;hello-world-web-part\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;path\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;dist/hello-world-web-part.js\u0026#34; }, \u0026#34;@custom/spfx-2019-lib\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;path\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;node_modules/@custom/spfx-2019-lib/dist/spfx2019lib.js\u0026#34;, \u0026#34;globalName\u0026#34;: \u0026#34;spfx2019lib_1_0_0\u0026#34; }, Now we deploy our solution and if we check our webpart we have excluded our code inside a single file @custom-spfx-2019-lib_f61c3320dcfac71474b84527be597369.js. It will also work with multiple webparts.\n  Finally we get to run our smart webpart with PnP.  Conclusion I hope this approach helps you to create better SPFX 2013 solutions and externalize your code in your own libraries. Here some small hints.\nGood:\n The code can shared between multiple webparts inside a solution You have full support of typings You can use other libraries inside your library (like PnP JS) You don\u0026rsquo;t have to care about versioning, it is still bundled inside your package You can share your library with other projects  Bad:\n You can not externalize React this way! Another story. Don\u0026rsquo;t externalize Office-Fabric-UI this way, similar to React. You cannot use other microsoft libraries inside your library (example @microsoft/sp-page-context)! The problem is, that the module loader can not load related sub libraries.  ","tags":["SPFX","SP2019","PnP","Library"],"section":"post"},{"date":"1613001600","url":"https://conception365.com/post/2021-02-11-orphaned-terms/","title":"Remove Managed Metadata Orphaned Terms","summary":"Problem In some cases you like to get rid of orphaned terms. Terms mostly get orphaned, if you reuse terms and delete the original instances. There is a very good explanation from Mike Morawski how this could happen.\n Not long ago I was working away with the term store though Powershell. I had to remove all of a particular group’s termsets and to do this I ended up calling the Group’s delete function.","content":"Problem In some cases you like to get rid of orphaned terms. Terms mostly get orphaned, if you reuse terms and delete the original instances. There is a very good explanation from Mike Morawski how this could happen.\n Not long ago I was working away with the term store though Powershell. I had to remove all of a particular group’s termsets and to do this I ended up calling the Group’s delete function. It appeared to work just fine, until I later found that I was unable to import terms with GUID’s used previously. This is somewhat of a common problem that developers will come across if they are saving certain terms or termsets and trying to reimport while the others with the same ID still exist.\nHowever, in this case, the entire term store was empty, until I realized that orphaned terms exist. For those of you who do not know the managed metadata service too well, orphaned terms will be created when deleting a term that was reused/pinned elsewhere. Because the original term that the ‘duplicates’ reference doesn’t exist anymore, the terms become orphans and they reside in the system group.\nThese orphaned terms get removed automatically when the duplicates are removed. Supposedly.\nThere appears to be a bug when removing a group through code where in certain cases the orphans never seem to be checked whether or not the duplicates have all been cleaned up. Through code I had to remove termsets one by one, using the group.termsets property, then commit. It seems that trying to do everything in one commit can cause this.\nNotice that the member of area indicates that there are no other terms using this as a reference, yet it still exists!\nAs far as removing the orphaned terms go, I was unable to actually target these terms through code as I would have the following error:\n This operation is invalid in the Orphaned Terms term set.\n Unfortunately I believe this leaves the MMS in a slightly corrupt state, it will still function so long as those GUID’s for the orphans are never used again. I ended up starting fresh because I fortunately ran into this before the code left the development server.\nI wish I could say more about this issue after the fact however this is all I can say for the time being. If you really need to remove these orphans, an idea I had a the time was to create a duplicate of that orphan through code, then remove manually though the interface and see if that causes some sort of event receiver to run through and clear the source term (orphan).\n You can also find some more details about general deleting of terms source.\nSolution There is a easy solution by deleting the terms with PNP Powershell. Prepare your environment:\nInstall-Module -Name PnP.PowerShell Delete your terms:\n$session = Get-PnPTaxonomySession $termStore = $session.TermStores[0] $termSet = Get-PnPTermSet -Identity \u0026#34;Orphaned Terms\u0026#34; -TermGroup \u0026#34;System\u0026#34; -Includes \u0026#34;Terms\u0026#34; if ($termSet) { $terms = $termSet.Terms $terms | ForEach-Object { $_.DeleteObject() } $termStore.CommitAll(); Invoke-PnPQuery } Thats everything!\n","tags":["SP2019","Powershell","PNP","Managed Metadata"],"section":"post"},{"date":"1607731200","url":"https://conception365.com/post/2020-12-12-managed-metadata-migration/","title":"Managed Metadata Migration","summary":"Managed metadata is a formal taxonomy classification system. A taxonomy groups the words, labels, and terms that describe something, and then arranges the groups into a hierarchy. You can learn more basics and wordings on microsoft docs. Mostly it is simple called term store.\nWhere are my data stored? The first common question for migration is, where actual the term store data are stored. The short answer is, everything important is stored in Managed Metadata SQL Database of the service application.","content":"Managed metadata is a formal taxonomy classification system. A taxonomy groups the words, labels, and terms that describe something, and then arranges the groups into a hierarchy. You can learn more basics and wordings on microsoft docs. Mostly it is simple called term store.\nWhere are my data stored? The first common question for migration is, where actual the term store data are stored. The short answer is, everything important is stored in Managed Metadata SQL Database of the service application. To get a bit deeper look we have to analyze the field structure.\nHow the fields are structured? A typical Sharepoint taxonomy field looks the following way (source).\n   DisplayName InternalName Data Type Visible Value Data Format Created By     [YourColumnName] [YourColumnName] TaxonomyFieldType[Mult] Yes 2;#Chennai WSS Id; Name of Team User   [YourColumnName]_0 [YourColumnName]TaxHTField0 Note No Chennai c61d9028-824f-446e-9389-eb9515813a42 Name of Term   Taxonomy Catch All Column TaxCatchAll Lookup No   SharePoint    We see here basically, there is one column [YourColumnName] for your term display value and another column [YourColumnName]TaxHTField0 for the term ID. But this is the internal structure, most time you handle with taxonomy fields by using the API, here everything internal is handled, and you don\u0026rsquo;t have to worry about the internal field. Sample for REST taxonomy structure\n{ \u0026#34;MetaSingleField\u0026#34;: { \u0026#34;__metadata\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;SP.Taxonomy.TaxonomyFieldValue\u0026#34; }, \u0026#34;Label\u0026#34;: \u0026#34;1289\u0026#34;, \u0026#34;TermGuid\u0026#34;: \u0026#34;0b032022-d156-49eb-9a48-904df5411349\u0026#34;, \u0026#34;WssId\u0026#34;: 1289 }, \u0026#34;MetaMultiField\u0026#34;: { \u0026#34;__metadata\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Collection(SP.Taxonomy.TaxonomyFieldValue)\u0026#34; }, \u0026#34;results\u0026#34;: [ { \u0026#34;Label\u0026#34;: \u0026#34; Label ABC\u0026#34;, \u0026#34;TermGuid\u0026#34;: \u0026#34;158a84f4-e5ff-440b-b55f-d30b0f77c402\u0026#34;, \u0026#34;WssId\u0026#34;: 1291 }, { \u0026#34;Label\u0026#34;: \u0026#34; Label DEF\u0026#34;, \u0026#34;TermGuid\u0026#34;: \u0026#34;03d2d388-a863-4f5d-818d-d71d948f763d\u0026#34;, \u0026#34;WssId\u0026#34;: 1290 } ] }, \u0026#34;TaxCatchAll\u0026#34;: { \u0026#34;results\u0026#34;: [ { \u0026#34;__metadata\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;158a84f4-e5ff-440b-b55f-d30b0f77c402\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SP.Data.TaxonomyHiddenListListItem\u0026#34; }, \u0026#34;ID\u0026#34;: 1291, \u0026#34;Term\u0026#34;: \u0026#34;Label ABC\u0026#34; }, { \u0026#34;__metadata\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;03d2d388-a863-4f5d-818d-d71d948f763d\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SP.Data.TaxonomyHiddenListListItem\u0026#34; }, \u0026#34;ID\u0026#34;: 1290, \u0026#34;Term\u0026#34;: \u0026#34;Label DEF\u0026#34; }, { \u0026#34;__metadata\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;0b032022-d156-49eb-9a48-904df5411349\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SP.Data.TaxonomyHiddenListListItem\u0026#34; }, \u0026#34;ID\u0026#34;: 1289, \u0026#34;Term\u0026#34;: \u0026#34;Label XYZ\u0026#34; } ] } } Why there is a hidden list? On the look of the field structure you also see a reference for WSS or TaxonomyHiddenList. The answer is, that is a caching system to allow get the taxonomy data faster from list only be a simple lookup to this hidden list. The good about this is, you d\u0026rsquo;ont have to really care about that fact. If you change taxonomy field values, SharePoint internal has Event Receivers to handle an update to this hidden list. If you are change the taxonomy value inside the term store, there is also an hourly update timer job, it makes an update to the hidden list information. So the result the quick conclusion from migration perspective is for that:\n Don\u0026rsquo;t care about hidden list on migration!  But there is a site collection and a global term store? Yes, the only real difference is the availability. So global term sets are visible on every site collection. Local term sets are only visible to a single site collection.\n Both sorts of terms are store on Managed Metadatabase  How are managed metadata fields and term store connected? A really important fact is, how the term store and fields are connected. We see more details by looking on the field structure.\n\u0026lt;Field Type=\u0026#34;TaxonomyFieldType\u0026#34; DisplayName=\u0026#34;Custom (web)\u0026#34; List=\u0026#34;Lists/TaxonomyHiddenList\u0026#34; WebId=\u0026#34;~sitecollection\u0026#34; ShowField=\u0026#34;Term1033\u0026#34; Required=\u0026#34;FALSE\u0026#34; EnforceUniqueValues=\u0026#34;FALSE\u0026#34; Group=\u0026#34;_Custom\u0026#34; ID=\u0026#34;{fce6a8e2-23e8-49c2-9bad-a534555296bb}\u0026#34; SourceID=\u0026#34;{5e68c9eb-5efe-4bcc-b8db-93d38d797fbe}\u0026#34; StaticName=\u0026#34;__Custom\u0026#34; Name=\u0026#34;__Custom\u0026#34; Overwrite=\u0026#34;TRUE\u0026#34;\u0026gt; Default /\u0026gt; \u0026lt;Customization\u0026gt; \u0026lt;ArrayOfProperty\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;SspId\u0026lt;/Name\u0026gt; \u0026lt;Value xmlns:q1=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; p4:type=\u0026#34;q1:string\u0026#34; xmlns:p4=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;b98dd270-8577-4db8-99e1-b9e894624fdb \u0026lt;/Value\u0026gt; \u0026lt;/Property\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;GroupId\u0026lt;/Name\u0026gt; \u0026lt;/Property\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;TermSetId\u0026lt;/Name\u0026gt; \u0026lt;Value xmlns:q2=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; p4:type=\u0026#34;q2:string\u0026#34; xmlns:p4=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;b7ae10cd-6c7c-4386-a1f2-7abec8e759e1 \u0026lt;/Value\u0026gt; \u0026lt;/Property\u0026gt; \u0026lt;Property\u0026gt; \u0026lt;Name\u0026gt;AnchorId\u0026lt;/Name\u0026gt; \u0026lt;Value xmlns:q3=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; p4:type=\u0026#34;q3:string\u0026#34; xmlns:p4=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt;00000000-0000-0000-0000-000000000000 \u0026lt;/Value\u0026gt; \u0026lt;/Property\u0026gt; ... \u0026lt;/ArrayOfProperty\u0026gt; \u0026lt;/Customization\u0026gt; \u0026lt;/Field\u0026gt; We find two important values:\n SspId: This is the ID of your managed metadata service application TermSetId: This is the ID of your termset  The consequence of these two information on migration perspective is.\n You need your Managed Metadata SQL Database and a related service application to keep your term store ID (SspID) You need always correct termset and term IDs for migration  Can I import or export my termsets? There are several import and export mechanisms here some details about:\n Taxonomy Import (details): It allows only to import simple csv based termsets without IDs, not for migration Export-SPMetadataWebServicePartitionData (details): It\u0026rsquo;s only for server to server migration from the same version Powershell Skripts (sample): You will keep your term set IDs, it can work for simple migrations only for term sets. If you have related data on your site collections, your term store ID could not match. Possible is first a database migration and afterwards a delta migration Migration tools: Mostly are relative close to Powershell Scripts PNP Powershell: Same like Powershell Scripts  In general, you have to think on these scenarios on a little more details:\n Handle users are not more available on target system Handle orphaned terms Handle term reuse Handle navigation term sets  How looks a database migration? To move the managed metadata database, take a copy only backup of it from your SQL server and then restore from files in your new SQL server. I took this short sample from here.\nAt this point, you already have a managed metadata service application in your target farm and you need to get it’s globally unique identifier (GUID). Run the following:\nGet-SPServiceApplication | ?{$_.name -like \u0026#34;*meta*\u0026#34;} | ft id You could put that ID in a variable, or you could type it into your next set of commands that attach the new db to the Managed Metadata service application\n$ServiceID = Get-SPServiceApplication | ?{$_.name -like \u0026#34;*meta*\u0026#34;} | ft id $mms = Get-SPServiceApplication -Identity $ServiceID Set-SPMetadataerviceApplication -Identity $mms -DatabaseName \u0026#34;MetaData\u0026#34; The key to this working is that the correct DatabaseName is used. So if your new db is named MetaDataDB, then the above script would need to be modified a little for the -DatabsaseName parameter.\nThe managed metadata navigation should now be working. If it’s not, just go to manage service applications, change the managed metadata database to a database that does not exist, click OK, then change it back. This process causes SharePoint to execute a timer job that syncs the service application up to the database.\n","tags":["SP2019","SP2013","Migration","Managed Metadata"],"section":"post"}]